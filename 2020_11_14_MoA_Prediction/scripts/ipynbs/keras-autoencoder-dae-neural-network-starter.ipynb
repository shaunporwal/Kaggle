{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:45.800870Z",
     "iopub.status.busy": "2020-11-29T19:14:45.800114Z",
     "iopub.status.idle": "2020-11-29T19:14:52.285174Z",
     "shell.execute_reply": "2020-11-29T19:14:52.284034Z"
    },
    "papermill": {
     "duration": 6.509864,
     "end_time": "2020-11-29T19:14:52.285298",
     "exception": false,
     "start_time": "2020-11-29T19:14:45.775434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:52.328583Z",
     "iopub.status.busy": "2020-11-29T19:14:52.326571Z",
     "iopub.status.idle": "2020-11-29T19:14:52.329313Z",
     "shell.execute_reply": "2020-11-29T19:14:52.329838Z"
    },
    "papermill": {
     "duration": 0.026183,
     "end_time": "2020-11-29T19:14:52.329966",
     "exception": false,
     "start_time": "2020-11-29T19:14:52.303783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01781,
     "end_time": "2020-11-29T19:14:52.366254",
     "exception": false,
     "start_time": "2020-11-29T19:14:52.348444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Current best version - 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:52.411445Z",
     "iopub.status.busy": "2020-11-29T19:14:52.410500Z",
     "iopub.status.idle": "2020-11-29T19:14:57.981011Z",
     "shell.execute_reply": "2020-11-29T19:14:57.979769Z"
    },
    "papermill": {
     "duration": 5.595749,
     "end_time": "2020-11-29T19:14:57.981153",
     "exception": false,
     "start_time": "2020-11-29T19:14:52.385404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.027005Z",
     "iopub.status.busy": "2020-11-29T19:14:58.025193Z",
     "iopub.status.idle": "2020-11-29T19:14:58.027753Z",
     "shell.execute_reply": "2020-11-29T19:14:58.028240Z"
    },
    "papermill": {
     "duration": 0.028842,
     "end_time": "2020-11-29T19:14:58.028361",
     "exception": false,
     "start_time": "2020-11-29T19:14:57.999519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n",
    "    del df['sig_id']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.073594Z",
     "iopub.status.busy": "2020-11-29T19:14:58.072943Z",
     "iopub.status.idle": "2020-11-29T19:14:58.095020Z",
     "shell.execute_reply": "2020-11-29T19:14:58.094308Z"
    },
    "papermill": {
     "duration": 0.04696,
     "end_time": "2020-11-29T19:14:58.095146",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.048186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.139433Z",
     "iopub.status.busy": "2020-11-29T19:14:58.137660Z",
     "iopub.status.idle": "2020-11-29T19:14:58.142081Z",
     "shell.execute_reply": "2020-11-29T19:14:58.141497Z"
    },
    "papermill": {
     "duration": 0.027694,
     "end_time": "2020-11-29T19:14:58.142176",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.114482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train_targets['sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.186728Z",
     "iopub.status.busy": "2020-11-29T19:14:58.185517Z",
     "iopub.status.idle": "2020-11-29T19:14:58.188007Z",
     "shell.execute_reply": "2020-11-29T19:14:58.188503Z"
    },
    "papermill": {
     "duration": 0.027219,
     "end_time": "2020-11-29T19:14:58.188617",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.161398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets['cp_type'] = train['cp_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.234759Z",
     "iopub.status.busy": "2020-11-29T19:14:58.234161Z",
     "iopub.status.idle": "2020-11-29T19:14:58.371811Z",
     "shell.execute_reply": "2020-11-29T19:14:58.371300Z"
    },
    "papermill": {
     "duration": 0.164886,
     "end_time": "2020-11-29T19:14:58.371929",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.207043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train['cp_type'] != 'ctl_vehicle']\n",
    "train_targets = train_targets[train_targets['cp_type'] != 'ctl_vehicle']\n",
    "\n",
    "train = train.drop(['cp_type'], axis=1)\n",
    "train_targets = train_targets.drop(['cp_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.415448Z",
     "iopub.status.busy": "2020-11-29T19:14:58.414317Z",
     "iopub.status.idle": "2020-11-29T19:14:58.581684Z",
     "shell.execute_reply": "2020-11-29T19:14:58.581172Z"
    },
    "papermill": {
     "duration": 0.190852,
     "end_time": "2020-11-29T19:14:58.581794",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.390942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index().drop(['index'], axis=1)\n",
    "train_targets = train_targets.reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.631560Z",
     "iopub.status.busy": "2020-11-29T19:14:58.629769Z",
     "iopub.status.idle": "2020-11-29T19:14:58.632337Z",
     "shell.execute_reply": "2020-11-29T19:14:58.632806Z"
    },
    "papermill": {
     "duration": 0.030588,
     "end_time": "2020-11-29T19:14:58.632930",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.602342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_categories = train[['cp_dose', 'cp_time']]\n",
    "test_categories = test[['cp_dose', 'cp_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.687441Z",
     "iopub.status.busy": "2020-11-29T19:14:58.686613Z",
     "iopub.status.idle": "2020-11-29T19:14:58.690027Z",
     "shell.execute_reply": "2020-11-29T19:14:58.689499Z"
    },
    "papermill": {
     "duration": 0.037488,
     "end_time": "2020-11-29T19:14:58.690143",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.652655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_cp_type = test['cp_type']\n",
    "test = test.drop(['cp_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.736990Z",
     "iopub.status.busy": "2020-11-29T19:14:58.736035Z",
     "iopub.status.idle": "2020-11-29T19:14:58.772719Z",
     "shell.execute_reply": "2020-11-29T19:14:58.773267Z"
    },
    "papermill": {
     "duration": 0.064354,
     "end_time": "2020-11-29T19:14:58.773402",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.709048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>-0.1777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>-0.4753</td>\n",
       "      <td>-0.2504</td>\n",
       "      <td>-0.7415</td>\n",
       "      <td>0.8413</td>\n",
       "      <td>-0.4259</td>\n",
       "      <td>0.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>-0.5565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose     g-0     g-1     g-2     g-3     g-4     g-5  \\\n",
       "0            0        0  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120   \n",
       "1            2        0  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207   \n",
       "2            1        0  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390   \n",
       "3            1        0 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095   \n",
       "4            2        1 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244   \n",
       "...        ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "21943        2        0  0.1608 -1.0500  0.2551 -0.2239 -0.2431  0.4256   \n",
       "21944        0        1  0.1394 -0.0636 -0.1112 -0.5080 -0.4713  0.7201   \n",
       "21945        0        1 -1.3260  0.3478 -0.3743  0.9905 -0.7178  0.6621   \n",
       "21946        0        0  0.6660  0.2324  0.4392  0.2044  0.8531 -0.0343   \n",
       "21947        2        0 -0.8598  1.0240 -0.1361  0.7952 -0.3611 -3.6750   \n",
       "\n",
       "          g-6     g-7  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0     -1.0220 -0.0326  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1      0.2341  0.3372  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2      0.1715  0.2155  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3     -1.9590  0.1792  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4     -0.2800 -0.1498  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "21943 -0.1166 -0.1777  ...  0.0789  0.3538  0.0558  0.3377 -0.4753 -0.2504   \n",
       "21944  0.5773  0.3055  ...  0.1969  0.0262 -0.8121  0.3434  0.5372 -0.3246   \n",
       "21945 -0.2252 -0.5565  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086 -0.9798   \n",
       "21946  0.0323  0.0463  ... -0.1105  0.4258 -0.2012  0.1506  1.5230  0.7101   \n",
       "21947 -1.2420  0.9146  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860 -1.4160   \n",
       "\n",
       "         c-96    c-97    c-98    c-99  \n",
       "0     -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4      0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...  \n",
       "21943 -0.7415  0.8413 -0.4259  0.2434  \n",
       "21944  0.0631  0.9171  0.5258  0.4680  \n",
       "21945 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "21946  0.1732  0.7015 -0.6290  0.0740  \n",
       "21947 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[21948 rows x 874 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.825622Z",
     "iopub.status.busy": "2020-11-29T19:14:58.824796Z",
     "iopub.status.idle": "2020-11-29T19:14:58.829066Z",
     "shell.execute_reply": "2020-11-29T19:14:58.828459Z"
    },
    "papermill": {
     "duration": 0.033743,
     "end_time": "2020-11-29T19:14:58.829167",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.795424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder():\n",
    "    input_vector = Input(shape=(874,))\n",
    "    encoded = Dense(3000, activation='elu')(input_vector)\n",
    "    encoded = Dense(2000, activation='elu')(encoded)\n",
    "    decoded = Dense(3000, activation='elu')(encoded)\n",
    "    decoded = Dense(874, activation='elu')(decoded)\n",
    "    \n",
    "    autoencoder = tf.keras.Model(\n",
    "        input_vector, \n",
    "        decoded\n",
    "    )\n",
    "    \n",
    "    autoencoder.compile(\n",
    "        optimizer='adadelta', \n",
    "        loss='mse'\n",
    "    )\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:14:58.875725Z",
     "iopub.status.busy": "2020-11-29T19:14:58.875126Z",
     "iopub.status.idle": "2020-11-29T19:15:01.426089Z",
     "shell.execute_reply": "2020-11-29T19:15:01.425471Z"
    },
    "papermill": {
     "duration": 2.574759,
     "end_time": "2020-11-29T19:15:01.426214",
     "exception": false,
     "start_time": "2020-11-29T19:14:58.851455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder = create_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:15:01.479768Z",
     "iopub.status.busy": "2020-11-29T19:15:01.476928Z",
     "iopub.status.idle": "2020-11-29T19:15:01.483448Z",
     "shell.execute_reply": "2020-11-29T19:15:01.480735Z"
    },
    "papermill": {
     "duration": 0.036721,
     "end_time": "2020-11-29T19:15:01.483739",
     "exception": false,
     "start_time": "2020-11-29T19:15:01.447018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 874)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3000)              2625000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              6002000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3000)              6003000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 874)               2622874   \n",
      "=================================================================\n",
      "Total params: 17,252,874\n",
      "Trainable params: 17,252,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:15:01.568485Z",
     "iopub.status.busy": "2020-11-29T19:15:01.567580Z",
     "iopub.status.idle": "2020-11-29T19:15:02.664873Z",
     "shell.execute_reply": "2020-11-29T19:15:02.665442Z"
    },
    "papermill": {
     "duration": 1.145642,
     "end_time": "2020-11-29T19:15:02.665597",
     "exception": false,
     "start_time": "2020-11-29T19:15:01.519955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.05\n",
    "\n",
    "noise = np.random.normal(\n",
    "    mu, \n",
    "    sigma, \n",
    "    [21948, 874]\n",
    ") \n",
    "noised_train = train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:15:02.715026Z",
     "iopub.status.busy": "2020-11-29T19:15:02.714447Z",
     "iopub.status.idle": "2020-11-29T19:31:33.890795Z",
     "shell.execute_reply": "2020-11-29T19:31:33.890301Z"
    },
    "papermill": {
     "duration": 991.202487,
     "end_time": "2020-11-29T19:31:33.890902",
     "exception": false,
     "start_time": "2020-11-29T19:15:02.688415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 2.0549 - val_loss: 1.9613\n",
      "Epoch 2/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.8969 - val_loss: 1.8440\n",
      "Epoch 3/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.8033 - val_loss: 1.7685\n",
      "Epoch 4/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.7388 - val_loss: 1.7133\n",
      "Epoch 5/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.6904 - val_loss: 1.6711\n",
      "Epoch 6/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.6532 - val_loss: 1.6385\n",
      "Epoch 7/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.6238 - val_loss: 1.6122\n",
      "Epoch 8/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.6003 - val_loss: 1.5915\n",
      "Epoch 9/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.5816 - val_loss: 1.5749\n",
      "Epoch 10/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5662 - val_loss: 1.5609\n",
      "Epoch 11/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5530 - val_loss: 1.5486\n",
      "Epoch 12/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5415 - val_loss: 1.5384\n",
      "Epoch 13/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5317 - val_loss: 1.5293\n",
      "Epoch 14/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5228 - val_loss: 1.5208\n",
      "Epoch 15/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5145 - val_loss: 1.5131\n",
      "Epoch 16/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.5069 - val_loss: 1.5059\n",
      "Epoch 17/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4998 - val_loss: 1.4991\n",
      "Epoch 18/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4930 - val_loss: 1.4927\n",
      "Epoch 19/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4866 - val_loss: 1.4867\n",
      "Epoch 20/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4805 - val_loss: 1.4810\n",
      "Epoch 21/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4748 - val_loss: 1.4755\n",
      "Epoch 22/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4693 - val_loss: 1.4702\n",
      "Epoch 23/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4639 - val_loss: 1.4650\n",
      "Epoch 24/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4587 - val_loss: 1.4600\n",
      "Epoch 25/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4536 - val_loss: 1.4551\n",
      "Epoch 26/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4485 - val_loss: 1.4501\n",
      "Epoch 27/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4435 - val_loss: 1.4452\n",
      "Epoch 28/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4386 - val_loss: 1.4405\n",
      "Epoch 29/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4337 - val_loss: 1.4358\n",
      "Epoch 30/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4289 - val_loss: 1.4312\n",
      "Epoch 31/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4243 - val_loss: 1.4269\n",
      "Epoch 32/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.4200 - val_loss: 1.4227\n",
      "Epoch 33/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4157 - val_loss: 1.4186\n",
      "Epoch 34/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.4116 - val_loss: 1.4146\n",
      "Epoch 35/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4075 - val_loss: 1.4107\n",
      "Epoch 36/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.4036 - val_loss: 1.4069\n",
      "Epoch 37/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3997 - val_loss: 1.4032\n",
      "Epoch 38/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3960 - val_loss: 1.3995\n",
      "Epoch 39/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3922 - val_loss: 1.3959\n",
      "Epoch 40/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3886 - val_loss: 1.3924\n",
      "Epoch 41/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3849 - val_loss: 1.3888\n",
      "Epoch 42/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.3813 - val_loss: 1.3852\n",
      "Epoch 43/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.3775 - val_loss: 1.3815\n",
      "Epoch 44/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3735 - val_loss: 1.3774\n",
      "Epoch 45/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3695 - val_loss: 1.3736\n",
      "Epoch 46/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3658 - val_loss: 1.3701\n",
      "Epoch 47/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3624 - val_loss: 1.3668\n",
      "Epoch 48/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.3591 - val_loss: 1.3637\n",
      "Epoch 49/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3559 - val_loss: 1.3606\n",
      "Epoch 50/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3528 - val_loss: 1.3576\n",
      "Epoch 51/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3498 - val_loss: 1.3547\n",
      "Epoch 52/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3468 - val_loss: 1.3519\n",
      "Epoch 53/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3439 - val_loss: 1.3491\n",
      "Epoch 54/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3411 - val_loss: 1.3463\n",
      "Epoch 55/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3382 - val_loss: 1.3436\n",
      "Epoch 56/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3355 - val_loss: 1.3409\n",
      "Epoch 57/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3328 - val_loss: 1.3383\n",
      "Epoch 58/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3301 - val_loss: 1.3358\n",
      "Epoch 59/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3275 - val_loss: 1.3332\n",
      "Epoch 60/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3249 - val_loss: 1.3307\n",
      "Epoch 61/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3224 - val_loss: 1.3283\n",
      "Epoch 62/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3199 - val_loss: 1.3259\n",
      "Epoch 63/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3175 - val_loss: 1.3235\n",
      "Epoch 64/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3150 - val_loss: 1.3212\n",
      "Epoch 65/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3127 - val_loss: 1.3189\n",
      "Epoch 66/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.3103 - val_loss: 1.3166\n",
      "Epoch 67/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.3080 - val_loss: 1.3144\n",
      "Epoch 68/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3057 - val_loss: 1.3122\n",
      "Epoch 69/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3035 - val_loss: 1.3100\n",
      "Epoch 70/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.3013 - val_loss: 1.3079\n",
      "Epoch 71/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2991 - val_loss: 1.3058\n",
      "Epoch 72/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2970 - val_loss: 1.3037\n",
      "Epoch 73/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2948 - val_loss: 1.3016\n",
      "Epoch 74/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2927 - val_loss: 1.2996\n",
      "Epoch 75/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2906 - val_loss: 1.2975\n",
      "Epoch 76/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2885 - val_loss: 1.2955\n",
      "Epoch 77/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.2865 - val_loss: 1.2936\n",
      "Epoch 78/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2845 - val_loss: 1.2916\n",
      "Epoch 79/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2825 - val_loss: 1.2897\n",
      "Epoch 80/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2806 - val_loss: 1.2879\n",
      "Epoch 81/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2787 - val_loss: 1.2860\n",
      "Epoch 82/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2768 - val_loss: 1.2842\n",
      "Epoch 83/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2750 - val_loss: 1.2824\n",
      "Epoch 84/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2731 - val_loss: 1.2806\n",
      "Epoch 85/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2713 - val_loss: 1.2789\n",
      "Epoch 86/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2695 - val_loss: 1.2772\n",
      "Epoch 87/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2678 - val_loss: 1.2755\n",
      "Epoch 88/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2660 - val_loss: 1.2738\n",
      "Epoch 89/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2643 - val_loss: 1.2721\n",
      "Epoch 90/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2626 - val_loss: 1.2705\n",
      "Epoch 91/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2609 - val_loss: 1.2688\n",
      "Epoch 92/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2593 - val_loss: 1.2672\n",
      "Epoch 93/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2576 - val_loss: 1.2657\n",
      "Epoch 94/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2560 - val_loss: 1.2641\n",
      "Epoch 95/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2544 - val_loss: 1.2625\n",
      "Epoch 96/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2528 - val_loss: 1.2610\n",
      "Epoch 97/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2513 - val_loss: 1.2595\n",
      "Epoch 98/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2497 - val_loss: 1.2580\n",
      "Epoch 99/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2482 - val_loss: 1.2565\n",
      "Epoch 100/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.2467 - val_loss: 1.2550\n",
      "Epoch 101/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2452 - val_loss: 1.2536\n",
      "Epoch 102/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2437 - val_loss: 1.2521\n",
      "Epoch 103/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.2422 - val_loss: 1.2507\n",
      "Epoch 104/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.2407 - val_loss: 1.2493\n",
      "Epoch 105/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2393 - val_loss: 1.2479\n",
      "Epoch 106/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2379 - val_loss: 1.2465\n",
      "Epoch 107/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2365 - val_loss: 1.2452\n",
      "Epoch 108/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2351 - val_loss: 1.2438\n",
      "Epoch 109/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2337 - val_loss: 1.2425\n",
      "Epoch 110/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2323 - val_loss: 1.2412\n",
      "Epoch 111/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2310 - val_loss: 1.2399\n",
      "Epoch 112/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2296 - val_loss: 1.2386\n",
      "Epoch 113/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2283 - val_loss: 1.2373\n",
      "Epoch 114/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2270 - val_loss: 1.2360\n",
      "Epoch 115/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2257 - val_loss: 1.2348\n",
      "Epoch 116/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2244 - val_loss: 1.2335\n",
      "Epoch 117/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2231 - val_loss: 1.2323\n",
      "Epoch 118/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2219 - val_loss: 1.2311\n",
      "Epoch 119/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2206 - val_loss: 1.2298\n",
      "Epoch 120/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2194 - val_loss: 1.2286\n",
      "Epoch 121/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2182 - val_loss: 1.2275\n",
      "Epoch 122/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.2170 - val_loss: 1.2263\n",
      "Epoch 123/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2157 - val_loss: 1.2251\n",
      "Epoch 124/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2146 - val_loss: 1.2240\n",
      "Epoch 125/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2134 - val_loss: 1.2228\n",
      "Epoch 126/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2122 - val_loss: 1.2217\n",
      "Epoch 127/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2110 - val_loss: 1.2205\n",
      "Epoch 128/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2099 - val_loss: 1.2194\n",
      "Epoch 129/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2087 - val_loss: 1.2183\n",
      "Epoch 130/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2076 - val_loss: 1.2172\n",
      "Epoch 131/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2065 - val_loss: 1.2161\n",
      "Epoch 132/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2054 - val_loss: 1.2151\n",
      "Epoch 133/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.2043 - val_loss: 1.2140\n",
      "Epoch 134/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.2032 - val_loss: 1.2129\n",
      "Epoch 135/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2021 - val_loss: 1.2119\n",
      "Epoch 136/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2010 - val_loss: 1.2108\n",
      "Epoch 137/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.2000 - val_loss: 1.2098\n",
      "Epoch 138/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1989 - val_loss: 1.2088\n",
      "Epoch 139/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1979 - val_loss: 1.2078\n",
      "Epoch 140/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1968 - val_loss: 1.2067\n",
      "Epoch 141/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1958 - val_loss: 1.2057\n",
      "Epoch 142/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1947 - val_loss: 1.2048\n",
      "Epoch 143/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1937 - val_loss: 1.2038\n",
      "Epoch 144/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1927 - val_loss: 1.2028\n",
      "Epoch 145/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1917 - val_loss: 1.2018\n",
      "Epoch 146/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1907 - val_loss: 1.2009\n",
      "Epoch 147/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1897 - val_loss: 1.1999\n",
      "Epoch 148/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1888 - val_loss: 1.1990\n",
      "Epoch 149/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1878 - val_loss: 1.1980\n",
      "Epoch 150/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1868 - val_loss: 1.1971\n",
      "Epoch 151/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1859 - val_loss: 1.1961\n",
      "Epoch 152/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1849 - val_loss: 1.1952\n",
      "Epoch 153/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1840 - val_loss: 1.1943\n",
      "Epoch 154/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1830 - val_loss: 1.1934\n",
      "Epoch 155/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1821 - val_loss: 1.1925\n",
      "Epoch 156/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1812 - val_loss: 1.1916\n",
      "Epoch 157/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1802 - val_loss: 1.1907\n",
      "Epoch 158/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1793 - val_loss: 1.1898\n",
      "Epoch 159/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1784 - val_loss: 1.1889\n",
      "Epoch 160/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1775 - val_loss: 1.1881\n",
      "Epoch 161/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1766 - val_loss: 1.1872\n",
      "Epoch 162/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1757 - val_loss: 1.1863\n",
      "Epoch 163/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1748 - val_loss: 1.1855\n",
      "Epoch 164/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1740 - val_loss: 1.1846\n",
      "Epoch 165/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1731 - val_loss: 1.1838\n",
      "Epoch 166/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1722 - val_loss: 1.1830\n",
      "Epoch 167/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1714 - val_loss: 1.1821\n",
      "Epoch 168/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1705 - val_loss: 1.1813\n",
      "Epoch 169/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1697 - val_loss: 1.1805\n",
      "Epoch 170/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1688 - val_loss: 1.1796\n",
      "Epoch 171/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1680 - val_loss: 1.1788\n",
      "Epoch 172/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1672 - val_loss: 1.1780\n",
      "Epoch 173/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1663 - val_loss: 1.1772\n",
      "Epoch 174/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1655 - val_loss: 1.1764\n",
      "Epoch 175/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1647 - val_loss: 1.1756\n",
      "Epoch 176/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1639 - val_loss: 1.1749\n",
      "Epoch 177/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1631 - val_loss: 1.1741\n",
      "Epoch 178/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1623 - val_loss: 1.1733\n",
      "Epoch 179/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1615 - val_loss: 1.1725\n",
      "Epoch 180/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1607 - val_loss: 1.1718\n",
      "Epoch 181/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1599 - val_loss: 1.1710\n",
      "Epoch 182/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1591 - val_loss: 1.1702\n",
      "Epoch 183/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1583 - val_loss: 1.1695\n",
      "Epoch 184/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1576 - val_loss: 1.1687\n",
      "Epoch 185/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1568 - val_loss: 1.1680\n",
      "Epoch 186/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1560 - val_loss: 1.1673\n",
      "Epoch 187/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1553 - val_loss: 1.1665\n",
      "Epoch 188/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1545 - val_loss: 1.1658\n",
      "Epoch 189/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1538 - val_loss: 1.1651\n",
      "Epoch 190/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1530 - val_loss: 1.1643\n",
      "Epoch 191/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1523 - val_loss: 1.1636\n",
      "Epoch 192/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1515 - val_loss: 1.1629\n",
      "Epoch 193/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1508 - val_loss: 1.1622\n",
      "Epoch 194/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1501 - val_loss: 1.1615\n",
      "Epoch 195/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1493 - val_loss: 1.1608\n",
      "Epoch 196/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1486 - val_loss: 1.1601\n",
      "Epoch 197/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1479 - val_loss: 1.1594\n",
      "Epoch 198/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1472 - val_loss: 1.1587\n",
      "Epoch 199/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1465 - val_loss: 1.1580\n",
      "Epoch 200/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1458 - val_loss: 1.1573\n",
      "Epoch 201/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1450 - val_loss: 1.1567\n",
      "Epoch 202/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1443 - val_loss: 1.1560\n",
      "Epoch 203/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1437 - val_loss: 1.1553\n",
      "Epoch 204/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1430 - val_loss: 1.1546\n",
      "Epoch 205/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1423 - val_loss: 1.1540\n",
      "Epoch 206/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1416 - val_loss: 1.1533\n",
      "Epoch 207/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1409 - val_loss: 1.1526\n",
      "Epoch 208/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1402 - val_loss: 1.1520\n",
      "Epoch 209/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1395 - val_loss: 1.1513\n",
      "Epoch 210/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1389 - val_loss: 1.1507\n",
      "Epoch 211/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1382 - val_loss: 1.1500\n",
      "Epoch 212/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1375 - val_loss: 1.1494\n",
      "Epoch 213/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1369 - val_loss: 1.1488\n",
      "Epoch 214/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1362 - val_loss: 1.1481\n",
      "Epoch 215/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1356 - val_loss: 1.1475\n",
      "Epoch 216/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1349 - val_loss: 1.1469\n",
      "Epoch 217/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1343 - val_loss: 1.1462\n",
      "Epoch 218/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1336 - val_loss: 1.1456\n",
      "Epoch 219/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1330 - val_loss: 1.1450\n",
      "Epoch 220/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1323 - val_loss: 1.1444\n",
      "Epoch 221/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1317 - val_loss: 1.1437\n",
      "Epoch 222/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1311 - val_loss: 1.1431\n",
      "Epoch 223/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1304 - val_loss: 1.1425\n",
      "Epoch 224/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1298 - val_loss: 1.1419\n",
      "Epoch 225/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1292 - val_loss: 1.1413\n",
      "Epoch 226/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1285 - val_loss: 1.1407\n",
      "Epoch 227/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1279 - val_loss: 1.1401\n",
      "Epoch 228/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1273 - val_loss: 1.1395\n",
      "Epoch 229/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1267 - val_loss: 1.1389\n",
      "Epoch 230/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1261 - val_loss: 1.1383\n",
      "Epoch 231/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1255 - val_loss: 1.1377\n",
      "Epoch 232/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1249 - val_loss: 1.1371\n",
      "Epoch 233/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1242 - val_loss: 1.1366\n",
      "Epoch 234/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1236 - val_loss: 1.1360\n",
      "Epoch 235/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1230 - val_loss: 1.1354\n",
      "Epoch 236/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1224 - val_loss: 1.1348\n",
      "Epoch 237/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1219 - val_loss: 1.1343\n",
      "Epoch 238/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1213 - val_loss: 1.1337\n",
      "Epoch 239/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1207 - val_loss: 1.1331\n",
      "Epoch 240/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1201 - val_loss: 1.1325\n",
      "Epoch 241/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1195 - val_loss: 1.1320\n",
      "Epoch 242/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1189 - val_loss: 1.1314\n",
      "Epoch 243/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1183 - val_loss: 1.1309\n",
      "Epoch 244/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1178 - val_loss: 1.1303\n",
      "Epoch 245/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1172 - val_loss: 1.1298\n",
      "Epoch 246/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1166 - val_loss: 1.1292\n",
      "Epoch 247/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1161 - val_loss: 1.1287\n",
      "Epoch 248/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1155 - val_loss: 1.1281\n",
      "Epoch 249/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1149 - val_loss: 1.1276\n",
      "Epoch 250/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1144 - val_loss: 1.1270\n",
      "Epoch 251/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1138 - val_loss: 1.1265\n",
      "Epoch 252/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1132 - val_loss: 1.1259\n",
      "Epoch 253/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1127 - val_loss: 1.1254\n",
      "Epoch 254/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1121 - val_loss: 1.1249\n",
      "Epoch 255/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1116 - val_loss: 1.1243\n",
      "Epoch 256/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1110 - val_loss: 1.1238\n",
      "Epoch 257/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1105 - val_loss: 1.1233\n",
      "Epoch 258/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1099 - val_loss: 1.1228\n",
      "Epoch 259/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1094 - val_loss: 1.1222\n",
      "Epoch 260/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1089 - val_loss: 1.1217\n",
      "Epoch 261/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1083 - val_loss: 1.1212\n",
      "Epoch 262/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1078 - val_loss: 1.1207\n",
      "Epoch 263/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1072 - val_loss: 1.1202\n",
      "Epoch 264/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1067 - val_loss: 1.1197\n",
      "Epoch 265/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.1062 - val_loss: 1.1191\n",
      "Epoch 266/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1057 - val_loss: 1.1186\n",
      "Epoch 267/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1051 - val_loss: 1.1181\n",
      "Epoch 268/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1046 - val_loss: 1.1176\n",
      "Epoch 269/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1041 - val_loss: 1.1171\n",
      "Epoch 270/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1036 - val_loss: 1.1166\n",
      "Epoch 271/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1030 - val_loss: 1.1161\n",
      "Epoch 272/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1025 - val_loss: 1.1156\n",
      "Epoch 273/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1020 - val_loss: 1.1151\n",
      "Epoch 274/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1015 - val_loss: 1.1146\n",
      "Epoch 275/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1010 - val_loss: 1.1141\n",
      "Epoch 276/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1005 - val_loss: 1.1136\n",
      "Epoch 277/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.1000 - val_loss: 1.1131\n",
      "Epoch 278/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0995 - val_loss: 1.1127\n",
      "Epoch 279/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0990 - val_loss: 1.1122\n",
      "Epoch 280/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0985 - val_loss: 1.1117\n",
      "Epoch 281/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0979 - val_loss: 1.1112\n",
      "Epoch 282/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0975 - val_loss: 1.1107\n",
      "Epoch 283/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0970 - val_loss: 1.1102\n",
      "Epoch 284/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0965 - val_loss: 1.1098\n",
      "Epoch 285/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0960 - val_loss: 1.1093\n",
      "Epoch 286/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0955 - val_loss: 1.1088\n",
      "Epoch 287/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0950 - val_loss: 1.1083\n",
      "Epoch 288/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0945 - val_loss: 1.1079\n",
      "Epoch 289/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0940 - val_loss: 1.1074\n",
      "Epoch 290/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0935 - val_loss: 1.1069\n",
      "Epoch 291/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0930 - val_loss: 1.1065\n",
      "Epoch 292/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0925 - val_loss: 1.1060\n",
      "Epoch 293/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0921 - val_loss: 1.1055\n",
      "Epoch 294/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0916 - val_loss: 1.1051\n",
      "Epoch 295/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0911 - val_loss: 1.1046\n",
      "Epoch 296/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0906 - val_loss: 1.1041\n",
      "Epoch 297/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0901 - val_loss: 1.1037\n",
      "Epoch 298/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0897 - val_loss: 1.1032\n",
      "Epoch 299/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0892 - val_loss: 1.1028\n",
      "Epoch 300/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0887 - val_loss: 1.1023\n",
      "Epoch 301/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0882 - val_loss: 1.1018\n",
      "Epoch 302/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0878 - val_loss: 1.1014\n",
      "Epoch 303/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0873 - val_loss: 1.1009\n",
      "Epoch 304/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0868 - val_loss: 1.1005\n",
      "Epoch 305/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0864 - val_loss: 1.1000\n",
      "Epoch 306/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0859 - val_loss: 1.0996\n",
      "Epoch 307/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0855 - val_loss: 1.0992\n",
      "Epoch 308/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0850 - val_loss: 1.0987\n",
      "Epoch 309/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0845 - val_loss: 1.0983\n",
      "Epoch 310/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0841 - val_loss: 1.0978\n",
      "Epoch 311/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0836 - val_loss: 1.0974\n",
      "Epoch 312/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0832 - val_loss: 1.0970\n",
      "Epoch 313/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0827 - val_loss: 1.0965\n",
      "Epoch 314/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0823 - val_loss: 1.0961\n",
      "Epoch 315/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0818 - val_loss: 1.0957\n",
      "Epoch 316/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0814 - val_loss: 1.0952\n",
      "Epoch 317/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0809 - val_loss: 1.0948\n",
      "Epoch 318/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0805 - val_loss: 1.0944\n",
      "Epoch 319/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0800 - val_loss: 1.0939\n",
      "Epoch 320/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0796 - val_loss: 1.0935\n",
      "Epoch 321/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0792 - val_loss: 1.0931\n",
      "Epoch 322/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0787 - val_loss: 1.0927\n",
      "Epoch 323/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0783 - val_loss: 1.0922\n",
      "Epoch 324/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0778 - val_loss: 1.0918\n",
      "Epoch 325/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0774 - val_loss: 1.0914\n",
      "Epoch 326/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0770 - val_loss: 1.0910\n",
      "Epoch 327/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0765 - val_loss: 1.0906\n",
      "Epoch 328/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0761 - val_loss: 1.0902\n",
      "Epoch 329/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0757 - val_loss: 1.0897\n",
      "Epoch 330/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0752 - val_loss: 1.0893\n",
      "Epoch 331/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0748 - val_loss: 1.0889\n",
      "Epoch 332/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0744 - val_loss: 1.0885\n",
      "Epoch 333/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0740 - val_loss: 1.0881\n",
      "Epoch 334/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0735 - val_loss: 1.0877\n",
      "Epoch 335/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0731 - val_loss: 1.0873\n",
      "Epoch 336/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0727 - val_loss: 1.0869\n",
      "Epoch 337/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0723 - val_loss: 1.0865\n",
      "Epoch 338/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0719 - val_loss: 1.0861\n",
      "Epoch 339/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0714 - val_loss: 1.0857\n",
      "Epoch 340/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0710 - val_loss: 1.0853\n",
      "Epoch 341/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0706 - val_loss: 1.0849\n",
      "Epoch 342/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0702 - val_loss: 1.0845\n",
      "Epoch 343/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0698 - val_loss: 1.0841\n",
      "Epoch 344/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0694 - val_loss: 1.0837\n",
      "Epoch 345/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0690 - val_loss: 1.0833\n",
      "Epoch 346/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0686 - val_loss: 1.0829\n",
      "Epoch 347/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0681 - val_loss: 1.0825\n",
      "Epoch 348/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0677 - val_loss: 1.0821\n",
      "Epoch 349/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0673 - val_loss: 1.0817\n",
      "Epoch 350/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0669 - val_loss: 1.0813\n",
      "Epoch 351/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0665 - val_loss: 1.0809\n",
      "Epoch 352/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0661 - val_loss: 1.0805\n",
      "Epoch 353/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0657 - val_loss: 1.0802\n",
      "Epoch 354/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0653 - val_loss: 1.0798\n",
      "Epoch 355/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0649 - val_loss: 1.0794\n",
      "Epoch 356/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0645 - val_loss: 1.0790\n",
      "Epoch 357/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0641 - val_loss: 1.0786\n",
      "Epoch 358/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0782\n",
      "Epoch 359/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0633 - val_loss: 1.0779\n",
      "Epoch 360/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0629 - val_loss: 1.0775\n",
      "Epoch 361/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0626 - val_loss: 1.0771\n",
      "Epoch 362/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0622 - val_loss: 1.0767\n",
      "Epoch 363/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0618 - val_loss: 1.0764\n",
      "Epoch 364/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0614 - val_loss: 1.0760\n",
      "Epoch 365/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0610 - val_loss: 1.0756\n",
      "Epoch 366/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0606 - val_loss: 1.0752\n",
      "Epoch 367/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0602 - val_loss: 1.0749\n",
      "Epoch 368/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0598 - val_loss: 1.0745\n",
      "Epoch 369/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0595 - val_loss: 1.0741\n",
      "Epoch 370/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0591 - val_loss: 1.0738\n",
      "Epoch 371/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0587 - val_loss: 1.0734\n",
      "Epoch 372/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0583 - val_loss: 1.0730\n",
      "Epoch 373/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0579 - val_loss: 1.0727\n",
      "Epoch 374/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0576 - val_loss: 1.0723\n",
      "Epoch 375/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0572 - val_loss: 1.0719\n",
      "Epoch 376/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0568 - val_loss: 1.0716\n",
      "Epoch 377/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0564 - val_loss: 1.0712\n",
      "Epoch 378/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0561 - val_loss: 1.0709\n",
      "Epoch 379/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0557 - val_loss: 1.0705\n",
      "Epoch 380/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0553 - val_loss: 1.0702\n",
      "Epoch 381/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0549 - val_loss: 1.0698\n",
      "Epoch 382/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0546 - val_loss: 1.0694\n",
      "Epoch 383/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0542 - val_loss: 1.0691\n",
      "Epoch 384/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0538 - val_loss: 1.0687\n",
      "Epoch 385/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0535 - val_loss: 1.0684\n",
      "Epoch 386/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0531 - val_loss: 1.0680\n",
      "Epoch 387/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0527 - val_loss: 1.0677\n",
      "Epoch 388/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0524 - val_loss: 1.0673\n",
      "Epoch 389/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0520 - val_loss: 1.0670\n",
      "Epoch 390/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0516 - val_loss: 1.0666\n",
      "Epoch 391/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0513 - val_loss: 1.0663\n",
      "Epoch 392/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0509 - val_loss: 1.0659\n",
      "Epoch 393/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0506 - val_loss: 1.0656\n",
      "Epoch 394/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0502 - val_loss: 1.0652\n",
      "Epoch 395/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0498 - val_loss: 1.0649\n",
      "Epoch 396/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0495 - val_loss: 1.0645\n",
      "Epoch 397/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0491 - val_loss: 1.0642\n",
      "Epoch 398/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0488 - val_loss: 1.0639\n",
      "Epoch 399/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0484 - val_loss: 1.0635\n",
      "Epoch 400/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0481 - val_loss: 1.0632\n",
      "Epoch 401/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0477 - val_loss: 1.0628\n",
      "Epoch 402/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0474 - val_loss: 1.0625\n",
      "Epoch 403/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0470 - val_loss: 1.0622\n",
      "Epoch 404/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0467 - val_loss: 1.0618\n",
      "Epoch 405/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0463 - val_loss: 1.0615\n",
      "Epoch 406/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0460 - val_loss: 1.0612\n",
      "Epoch 407/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0456 - val_loss: 1.0608\n",
      "Epoch 408/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0453 - val_loss: 1.0605\n",
      "Epoch 409/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0449 - val_loss: 1.0602\n",
      "Epoch 410/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0446 - val_loss: 1.0598\n",
      "Epoch 411/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0442 - val_loss: 1.0595\n",
      "Epoch 412/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0439 - val_loss: 1.0592\n",
      "Epoch 413/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0435 - val_loss: 1.0588\n",
      "Epoch 414/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0432 - val_loss: 1.0585\n",
      "Epoch 415/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0429 - val_loss: 1.0582\n",
      "Epoch 416/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0425 - val_loss: 1.0579\n",
      "Epoch 417/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0422 - val_loss: 1.0575\n",
      "Epoch 418/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0418 - val_loss: 1.0572\n",
      "Epoch 419/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0415 - val_loss: 1.0569\n",
      "Epoch 420/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0412 - val_loss: 1.0565\n",
      "Epoch 421/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0408 - val_loss: 1.0562\n",
      "Epoch 422/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0405 - val_loss: 1.0559\n",
      "Epoch 423/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0402 - val_loss: 1.0556\n",
      "Epoch 424/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0398 - val_loss: 1.0553\n",
      "Epoch 425/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0395 - val_loss: 1.0549\n",
      "Epoch 426/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0392 - val_loss: 1.0546\n",
      "Epoch 427/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0388 - val_loss: 1.0543\n",
      "Epoch 428/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0385 - val_loss: 1.0540\n",
      "Epoch 429/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0382 - val_loss: 1.0537\n",
      "Epoch 430/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0378 - val_loss: 1.0533\n",
      "Epoch 431/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0375 - val_loss: 1.0530\n",
      "Epoch 432/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0372 - val_loss: 1.0527\n",
      "Epoch 433/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0369 - val_loss: 1.0524\n",
      "Epoch 434/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0365 - val_loss: 1.0521\n",
      "Epoch 435/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0362 - val_loss: 1.0518\n",
      "Epoch 436/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0359 - val_loss: 1.0515\n",
      "Epoch 437/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0356 - val_loss: 1.0511\n",
      "Epoch 438/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0352 - val_loss: 1.0508\n",
      "Epoch 439/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0349 - val_loss: 1.0505\n",
      "Epoch 440/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0346 - val_loss: 1.0502\n",
      "Epoch 441/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0343 - val_loss: 1.0499\n",
      "Epoch 442/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0339 - val_loss: 1.0496\n",
      "Epoch 443/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0336 - val_loss: 1.0493\n",
      "Epoch 444/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0333 - val_loss: 1.0490\n",
      "Epoch 445/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0330 - val_loss: 1.0487\n",
      "Epoch 446/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0327 - val_loss: 1.0484\n",
      "Epoch 447/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0324 - val_loss: 1.0481\n",
      "Epoch 448/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0320 - val_loss: 1.0478\n",
      "Epoch 449/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0317 - val_loss: 1.0475\n",
      "Epoch 450/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0314 - val_loss: 1.0472\n",
      "Epoch 451/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0311 - val_loss: 1.0469\n",
      "Epoch 452/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0308 - val_loss: 1.0466\n",
      "Epoch 453/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0305 - val_loss: 1.0463\n",
      "Epoch 454/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0301 - val_loss: 1.0459\n",
      "Epoch 455/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0298 - val_loss: 1.0456\n",
      "Epoch 456/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0295 - val_loss: 1.0453\n",
      "Epoch 457/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0292 - val_loss: 1.0451\n",
      "Epoch 458/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0289 - val_loss: 1.0448\n",
      "Epoch 459/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0286 - val_loss: 1.0445\n",
      "Epoch 460/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0283 - val_loss: 1.0442\n",
      "Epoch 461/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0280 - val_loss: 1.0439\n",
      "Epoch 462/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0277 - val_loss: 1.0436\n",
      "Epoch 463/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0274 - val_loss: 1.0433\n",
      "Epoch 464/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0271 - val_loss: 1.0430\n",
      "Epoch 465/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0268 - val_loss: 1.0427\n",
      "Epoch 466/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0265 - val_loss: 1.0424\n",
      "Epoch 467/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0261 - val_loss: 1.0421\n",
      "Epoch 468/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0258 - val_loss: 1.0418\n",
      "Epoch 469/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0255 - val_loss: 1.0415\n",
      "Epoch 470/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0252 - val_loss: 1.0412\n",
      "Epoch 471/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0249 - val_loss: 1.0409\n",
      "Epoch 472/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0246 - val_loss: 1.0407\n",
      "Epoch 473/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0243 - val_loss: 1.0404\n",
      "Epoch 474/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0240 - val_loss: 1.0401\n",
      "Epoch 475/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0237 - val_loss: 1.0398\n",
      "Epoch 476/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0234 - val_loss: 1.0395\n",
      "Epoch 477/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0231 - val_loss: 1.0392\n",
      "Epoch 478/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0228 - val_loss: 1.0389\n",
      "Epoch 479/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0225 - val_loss: 1.0386\n",
      "Epoch 480/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0223 - val_loss: 1.0384\n",
      "Epoch 481/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0220 - val_loss: 1.0381\n",
      "Epoch 482/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0217 - val_loss: 1.0378\n",
      "Epoch 483/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0214 - val_loss: 1.0375\n",
      "Epoch 484/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0211 - val_loss: 1.0372\n",
      "Epoch 485/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0208 - val_loss: 1.0369\n",
      "Epoch 486/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0205 - val_loss: 1.0367\n",
      "Epoch 487/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0202 - val_loss: 1.0364\n",
      "Epoch 488/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0199 - val_loss: 1.0361\n",
      "Epoch 489/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0196 - val_loss: 1.0358\n",
      "Epoch 490/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0193 - val_loss: 1.0355\n",
      "Epoch 491/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0190 - val_loss: 1.0353\n",
      "Epoch 492/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0187 - val_loss: 1.0350\n",
      "Epoch 493/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0185 - val_loss: 1.0347\n",
      "Epoch 494/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0182 - val_loss: 1.0344\n",
      "Epoch 495/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0179 - val_loss: 1.0342\n",
      "Epoch 496/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0176 - val_loss: 1.0339\n",
      "Epoch 497/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0173 - val_loss: 1.0336\n",
      "Epoch 498/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0170 - val_loss: 1.0333\n",
      "Epoch 499/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0167 - val_loss: 1.0331\n",
      "Epoch 500/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0164 - val_loss: 1.0328\n",
      "Epoch 501/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0162 - val_loss: 1.0325\n",
      "Epoch 502/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0159 - val_loss: 1.0322\n",
      "Epoch 503/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0156 - val_loss: 1.0320\n",
      "Epoch 504/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0153 - val_loss: 1.0317\n",
      "Epoch 505/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0150 - val_loss: 1.0314\n",
      "Epoch 506/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0147 - val_loss: 1.0312\n",
      "Epoch 507/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0145 - val_loss: 1.0309\n",
      "Epoch 508/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0142 - val_loss: 1.0306\n",
      "Epoch 509/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0139 - val_loss: 1.0303\n",
      "Epoch 510/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0136 - val_loss: 1.0301\n",
      "Epoch 511/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0133 - val_loss: 1.0298\n",
      "Epoch 512/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0131 - val_loss: 1.0295\n",
      "Epoch 513/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0128 - val_loss: 1.0293\n",
      "Epoch 514/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0125 - val_loss: 1.0290\n",
      "Epoch 515/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0122 - val_loss: 1.0288\n",
      "Epoch 516/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0120 - val_loss: 1.0285\n",
      "Epoch 517/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0117 - val_loss: 1.0282\n",
      "Epoch 518/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0114 - val_loss: 1.0279\n",
      "Epoch 519/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0111 - val_loss: 1.0277\n",
      "Epoch 520/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0108 - val_loss: 1.0274\n",
      "Epoch 521/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0106 - val_loss: 1.0272\n",
      "Epoch 522/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0103 - val_loss: 1.0269\n",
      "Epoch 523/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0100 - val_loss: 1.0266\n",
      "Epoch 524/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0098 - val_loss: 1.0264\n",
      "Epoch 525/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0095 - val_loss: 1.0261\n",
      "Epoch 526/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0092 - val_loss: 1.0258\n",
      "Epoch 527/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0089 - val_loss: 1.0256\n",
      "Epoch 528/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0087 - val_loss: 1.0253\n",
      "Epoch 529/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0084 - val_loss: 1.0250\n",
      "Epoch 530/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0081 - val_loss: 1.0248\n",
      "Epoch 531/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0078 - val_loss: 1.0245\n",
      "Epoch 532/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0076 - val_loss: 1.0243\n",
      "Epoch 533/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0073 - val_loss: 1.0240\n",
      "Epoch 534/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0070 - val_loss: 1.0238\n",
      "Epoch 535/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0068 - val_loss: 1.0235\n",
      "Epoch 536/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0065 - val_loss: 1.0233\n",
      "Epoch 537/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0062 - val_loss: 1.0230\n",
      "Epoch 538/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0060 - val_loss: 1.0227\n",
      "Epoch 539/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0057 - val_loss: 1.0225\n",
      "Epoch 540/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0054 - val_loss: 1.0222\n",
      "Epoch 541/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0052 - val_loss: 1.0220\n",
      "Epoch 542/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0049 - val_loss: 1.0217\n",
      "Epoch 543/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0046 - val_loss: 1.0215\n",
      "Epoch 544/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0044 - val_loss: 1.0212\n",
      "Epoch 545/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0041 - val_loss: 1.0210\n",
      "Epoch 546/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0039 - val_loss: 1.0207\n",
      "Epoch 547/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0036 - val_loss: 1.0204\n",
      "Epoch 548/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0033 - val_loss: 1.0202\n",
      "Epoch 549/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0031 - val_loss: 1.0199\n",
      "Epoch 550/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0028 - val_loss: 1.0197\n",
      "Epoch 551/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0025 - val_loss: 1.0194\n",
      "Epoch 552/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0023 - val_loss: 1.0192\n",
      "Epoch 553/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0020 - val_loss: 1.0189\n",
      "Epoch 554/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0018 - val_loss: 1.0187\n",
      "Epoch 555/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0015 - val_loss: 1.0184\n",
      "Epoch 556/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0012 - val_loss: 1.0182\n",
      "Epoch 557/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 1.0010 - val_loss: 1.0179\n",
      "Epoch 558/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0007 - val_loss: 1.0177\n",
      "Epoch 559/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0005 - val_loss: 1.0174\n",
      "Epoch 560/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0002 - val_loss: 1.0172\n",
      "Epoch 561/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9999 - val_loss: 1.0170\n",
      "Epoch 562/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9997 - val_loss: 1.0167\n",
      "Epoch 563/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9994 - val_loss: 1.0165\n",
      "Epoch 564/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9992 - val_loss: 1.0162\n",
      "Epoch 565/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9989 - val_loss: 1.0160\n",
      "Epoch 566/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9987 - val_loss: 1.0157\n",
      "Epoch 567/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9984 - val_loss: 1.0155\n",
      "Epoch 568/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9982 - val_loss: 1.0152\n",
      "Epoch 569/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9979 - val_loss: 1.0150\n",
      "Epoch 570/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9977 - val_loss: 1.0148\n",
      "Epoch 571/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9974 - val_loss: 1.0145\n",
      "Epoch 572/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9972 - val_loss: 1.0143\n",
      "Epoch 573/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9969 - val_loss: 1.0140\n",
      "Epoch 574/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9967 - val_loss: 1.0138\n",
      "Epoch 575/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9964 - val_loss: 1.0136\n",
      "Epoch 576/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9962 - val_loss: 1.0133\n",
      "Epoch 577/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9959 - val_loss: 1.0131\n",
      "Epoch 578/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9957 - val_loss: 1.0128\n",
      "Epoch 579/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9954 - val_loss: 1.0126\n",
      "Epoch 580/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9952 - val_loss: 1.0124\n",
      "Epoch 581/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9949 - val_loss: 1.0121\n",
      "Epoch 582/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9947 - val_loss: 1.0119\n",
      "Epoch 583/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9944 - val_loss: 1.0117\n",
      "Epoch 584/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9942 - val_loss: 1.0114\n",
      "Epoch 585/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9939 - val_loss: 1.0112\n",
      "Epoch 586/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9937 - val_loss: 1.0109\n",
      "Epoch 587/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9934 - val_loss: 1.0107\n",
      "Epoch 588/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9932 - val_loss: 1.0105\n",
      "Epoch 589/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9929 - val_loss: 1.0102\n",
      "Epoch 590/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9927 - val_loss: 1.0100\n",
      "Epoch 591/1000\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.9925 - val_loss: 1.0098\n",
      "Epoch 592/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9922 - val_loss: 1.0095\n",
      "Epoch 593/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9920 - val_loss: 1.0093\n",
      "Epoch 594/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9917 - val_loss: 1.0091\n",
      "Epoch 595/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9915 - val_loss: 1.0088\n",
      "Epoch 596/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9912 - val_loss: 1.0086\n",
      "Epoch 597/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9910 - val_loss: 1.0084\n",
      "Epoch 598/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9908 - val_loss: 1.0081\n",
      "Epoch 599/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9905 - val_loss: 1.0079\n",
      "Epoch 600/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9903 - val_loss: 1.0077\n",
      "Epoch 601/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9900 - val_loss: 1.0074\n",
      "Epoch 602/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9898 - val_loss: 1.0072\n",
      "Epoch 603/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9896 - val_loss: 1.0070\n",
      "Epoch 604/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9893 - val_loss: 1.0068\n",
      "Epoch 605/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9891 - val_loss: 1.0065\n",
      "Epoch 606/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9889 - val_loss: 1.0063\n",
      "Epoch 607/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9886 - val_loss: 1.0061\n",
      "Epoch 608/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9884 - val_loss: 1.0058\n",
      "Epoch 609/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9881 - val_loss: 1.0056\n",
      "Epoch 610/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9879 - val_loss: 1.0054\n",
      "Epoch 611/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9877 - val_loss: 1.0052\n",
      "Epoch 612/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9874 - val_loss: 1.0049\n",
      "Epoch 613/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9872 - val_loss: 1.0047\n",
      "Epoch 614/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9870 - val_loss: 1.0045\n",
      "Epoch 615/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9867 - val_loss: 1.0043\n",
      "Epoch 616/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9865 - val_loss: 1.0040\n",
      "Epoch 617/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9863 - val_loss: 1.0038\n",
      "Epoch 618/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9860 - val_loss: 1.0036\n",
      "Epoch 619/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9858 - val_loss: 1.0034\n",
      "Epoch 620/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9856 - val_loss: 1.0031\n",
      "Epoch 621/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9853 - val_loss: 1.0029\n",
      "Epoch 622/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9851 - val_loss: 1.0027\n",
      "Epoch 623/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9849 - val_loss: 1.0025\n",
      "Epoch 624/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9846 - val_loss: 1.0022\n",
      "Epoch 625/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9844 - val_loss: 1.0020\n",
      "Epoch 626/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9842 - val_loss: 1.0018\n",
      "Epoch 627/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9839 - val_loss: 1.0016\n",
      "Epoch 628/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9837 - val_loss: 1.0014\n",
      "Epoch 629/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9835 - val_loss: 1.0011\n",
      "Epoch 630/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9832 - val_loss: 1.0009\n",
      "Epoch 631/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9830 - val_loss: 1.0007\n",
      "Epoch 632/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9828 - val_loss: 1.0005\n",
      "Epoch 633/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9826 - val_loss: 1.0003\n",
      "Epoch 634/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9823 - val_loss: 1.0000\n",
      "Epoch 635/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9821 - val_loss: 0.9998\n",
      "Epoch 636/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9819 - val_loss: 0.9996\n",
      "Epoch 637/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9817 - val_loss: 0.9994\n",
      "Epoch 638/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9814 - val_loss: 0.9992\n",
      "Epoch 639/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9812 - val_loss: 0.9990\n",
      "Epoch 640/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9810 - val_loss: 0.9987\n",
      "Epoch 641/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9808 - val_loss: 0.9985\n",
      "Epoch 642/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9805 - val_loss: 0.9983\n",
      "Epoch 643/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9803 - val_loss: 0.9981\n",
      "Epoch 644/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9801 - val_loss: 0.9979\n",
      "Epoch 645/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.9799 - val_loss: 0.9977\n",
      "Epoch 646/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9796 - val_loss: 0.9974\n",
      "Epoch 647/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9794 - val_loss: 0.9972\n",
      "Epoch 648/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9792 - val_loss: 0.9970\n",
      "Epoch 649/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9790 - val_loss: 0.9968\n",
      "Epoch 650/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9787 - val_loss: 0.9966\n",
      "Epoch 651/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9785 - val_loss: 0.9964\n",
      "Epoch 652/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9783 - val_loss: 0.9962\n",
      "Epoch 653/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9781 - val_loss: 0.9960\n",
      "Epoch 654/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9779 - val_loss: 0.9957\n",
      "Epoch 655/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9776 - val_loss: 0.9955\n",
      "Epoch 656/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9774 - val_loss: 0.9953\n",
      "Epoch 657/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9772 - val_loss: 0.9951\n",
      "Epoch 658/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9770 - val_loss: 0.9949\n",
      "Epoch 659/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9768 - val_loss: 0.9947\n",
      "Epoch 660/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9765 - val_loss: 0.9945\n",
      "Epoch 661/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9763 - val_loss: 0.9943\n",
      "Epoch 662/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9761 - val_loss: 0.9941\n",
      "Epoch 663/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9759 - val_loss: 0.9939\n",
      "Epoch 664/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9757 - val_loss: 0.9936\n",
      "Epoch 665/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9755 - val_loss: 0.9934\n",
      "Epoch 666/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9752 - val_loss: 0.9932\n",
      "Epoch 667/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9750 - val_loss: 0.9930\n",
      "Epoch 668/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9748 - val_loss: 0.9928\n",
      "Epoch 669/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9746 - val_loss: 0.9926\n",
      "Epoch 670/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9744 - val_loss: 0.9924\n",
      "Epoch 671/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9742 - val_loss: 0.9922\n",
      "Epoch 672/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9739 - val_loss: 0.9920\n",
      "Epoch 673/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9737 - val_loss: 0.9918\n",
      "Epoch 674/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9735 - val_loss: 0.9916\n",
      "Epoch 675/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9733 - val_loss: 0.9914\n",
      "Epoch 676/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9731 - val_loss: 0.9912\n",
      "Epoch 677/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9729 - val_loss: 0.9910\n",
      "Epoch 678/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9727 - val_loss: 0.9907\n",
      "Epoch 679/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9725 - val_loss: 0.9905\n",
      "Epoch 680/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9722 - val_loss: 0.9903\n",
      "Epoch 681/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9720 - val_loss: 0.9901\n",
      "Epoch 682/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9718 - val_loss: 0.9899\n",
      "Epoch 683/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9716 - val_loss: 0.9897\n",
      "Epoch 684/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9714 - val_loss: 0.9895\n",
      "Epoch 685/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9712 - val_loss: 0.9893\n",
      "Epoch 686/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9710 - val_loss: 0.9891\n",
      "Epoch 687/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9708 - val_loss: 0.9889\n",
      "Epoch 688/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9706 - val_loss: 0.9887\n",
      "Epoch 689/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9703 - val_loss: 0.9885\n",
      "Epoch 690/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9701 - val_loss: 0.9883\n",
      "Epoch 691/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9699 - val_loss: 0.9881\n",
      "Epoch 692/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9697 - val_loss: 0.9879\n",
      "Epoch 693/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9695 - val_loss: 0.9877\n",
      "Epoch 694/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9693 - val_loss: 0.9875\n",
      "Epoch 695/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9691 - val_loss: 0.9873\n",
      "Epoch 696/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9689 - val_loss: 0.9871\n",
      "Epoch 697/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9687 - val_loss: 0.9869\n",
      "Epoch 698/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9685 - val_loss: 0.9867\n",
      "Epoch 699/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9683 - val_loss: 0.9865\n",
      "Epoch 700/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9681 - val_loss: 0.9863\n",
      "Epoch 701/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9679 - val_loss: 0.9861\n",
      "Epoch 702/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9677 - val_loss: 0.9859\n",
      "Epoch 703/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9675 - val_loss: 0.9857\n",
      "Epoch 704/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9672 - val_loss: 0.9855\n",
      "Epoch 705/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9670 - val_loss: 0.9853\n",
      "Epoch 706/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9668 - val_loss: 0.9851\n",
      "Epoch 707/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9666 - val_loss: 0.9850\n",
      "Epoch 708/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9664 - val_loss: 0.9848\n",
      "Epoch 709/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9662 - val_loss: 0.9846\n",
      "Epoch 710/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9660 - val_loss: 0.9844\n",
      "Epoch 711/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9658 - val_loss: 0.9842\n",
      "Epoch 712/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9656 - val_loss: 0.9840\n",
      "Epoch 713/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9654 - val_loss: 0.9838\n",
      "Epoch 714/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9652 - val_loss: 0.9836\n",
      "Epoch 715/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9650 - val_loss: 0.9834\n",
      "Epoch 716/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9648 - val_loss: 0.9832\n",
      "Epoch 717/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9646 - val_loss: 0.9830\n",
      "Epoch 718/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9644 - val_loss: 0.9828\n",
      "Epoch 719/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9642 - val_loss: 0.9826\n",
      "Epoch 720/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9640 - val_loss: 0.9824\n",
      "Epoch 721/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9638 - val_loss: 0.9822\n",
      "Epoch 722/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9636 - val_loss: 0.9820\n",
      "Epoch 723/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9634 - val_loss: 0.9818\n",
      "Epoch 724/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9632 - val_loss: 0.9817\n",
      "Epoch 725/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9630 - val_loss: 0.9815\n",
      "Epoch 726/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9628 - val_loss: 0.9813\n",
      "Epoch 727/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9626 - val_loss: 0.9811\n",
      "Epoch 728/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9624 - val_loss: 0.9809\n",
      "Epoch 729/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9622 - val_loss: 0.9807\n",
      "Epoch 730/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9620 - val_loss: 0.9805\n",
      "Epoch 731/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9618 - val_loss: 0.9803\n",
      "Epoch 732/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9616 - val_loss: 0.9801\n",
      "Epoch 733/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9614 - val_loss: 0.9799\n",
      "Epoch 734/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9612 - val_loss: 0.9797\n",
      "Epoch 735/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9610 - val_loss: 0.9796\n",
      "Epoch 736/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9608 - val_loss: 0.9794\n",
      "Epoch 737/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9606 - val_loss: 0.9792\n",
      "Epoch 738/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9604 - val_loss: 0.9790\n",
      "Epoch 739/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9602 - val_loss: 0.9788\n",
      "Epoch 740/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9601 - val_loss: 0.9786\n",
      "Epoch 741/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9599 - val_loss: 0.9784\n",
      "Epoch 742/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9597 - val_loss: 0.9782\n",
      "Epoch 743/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9595 - val_loss: 0.9781\n",
      "Epoch 744/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9593 - val_loss: 0.9779\n",
      "Epoch 745/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9591 - val_loss: 0.9777\n",
      "Epoch 746/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9589 - val_loss: 0.9775\n",
      "Epoch 747/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9587 - val_loss: 0.9773\n",
      "Epoch 748/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9585 - val_loss: 0.9771\n",
      "Epoch 749/1000\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.9583 - val_loss: 0.9769\n",
      "Epoch 750/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9581 - val_loss: 0.9768\n",
      "Epoch 751/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9579 - val_loss: 0.9766\n",
      "Epoch 752/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9577 - val_loss: 0.9764\n",
      "Epoch 753/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9575 - val_loss: 0.9762\n",
      "Epoch 754/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9573 - val_loss: 0.9760\n",
      "Epoch 755/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9572 - val_loss: 0.9758\n",
      "Epoch 756/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9570 - val_loss: 0.9756\n",
      "Epoch 757/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9568 - val_loss: 0.9755\n",
      "Epoch 758/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9566 - val_loss: 0.9753\n",
      "Epoch 759/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9564 - val_loss: 0.9751\n",
      "Epoch 760/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9562 - val_loss: 0.9749\n",
      "Epoch 761/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9560 - val_loss: 0.9747\n",
      "Epoch 762/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9558 - val_loss: 0.9745\n",
      "Epoch 763/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9556 - val_loss: 0.9744\n",
      "Epoch 764/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9554 - val_loss: 0.9742\n",
      "Epoch 765/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9553 - val_loss: 0.9740\n",
      "Epoch 766/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9551 - val_loss: 0.9738\n",
      "Epoch 767/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9549 - val_loss: 0.9736\n",
      "Epoch 768/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9547 - val_loss: 0.9735\n",
      "Epoch 769/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9545 - val_loss: 0.9733\n",
      "Epoch 770/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9543 - val_loss: 0.9731\n",
      "Epoch 771/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9541 - val_loss: 0.9729\n",
      "Epoch 772/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9539 - val_loss: 0.9727\n",
      "Epoch 773/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9538 - val_loss: 0.9726\n",
      "Epoch 774/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9536 - val_loss: 0.9724\n",
      "Epoch 775/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9534 - val_loss: 0.9722\n",
      "Epoch 776/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9532 - val_loss: 0.9720\n",
      "Epoch 777/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9530 - val_loss: 0.9718\n",
      "Epoch 778/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9528 - val_loss: 0.9717\n",
      "Epoch 779/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9526 - val_loss: 0.9715\n",
      "Epoch 780/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9525 - val_loss: 0.9713\n",
      "Epoch 781/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9523 - val_loss: 0.9711\n",
      "Epoch 782/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9521 - val_loss: 0.9709\n",
      "Epoch 783/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9519 - val_loss: 0.9708\n",
      "Epoch 784/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9517 - val_loss: 0.9706\n",
      "Epoch 785/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9515 - val_loss: 0.9704\n",
      "Epoch 786/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9513 - val_loss: 0.9702\n",
      "Epoch 787/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9512 - val_loss: 0.9701\n",
      "Epoch 788/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9510 - val_loss: 0.9699\n",
      "Epoch 789/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9508 - val_loss: 0.9697\n",
      "Epoch 790/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9506 - val_loss: 0.9695\n",
      "Epoch 791/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9504 - val_loss: 0.9694\n",
      "Epoch 792/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9502 - val_loss: 0.9692\n",
      "Epoch 793/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9501 - val_loss: 0.9690\n",
      "Epoch 794/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9499 - val_loss: 0.9688\n",
      "Epoch 795/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9497 - val_loss: 0.9687\n",
      "Epoch 796/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9495 - val_loss: 0.9685\n",
      "Epoch 797/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9493 - val_loss: 0.9683\n",
      "Epoch 798/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9492 - val_loss: 0.9681\n",
      "Epoch 799/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9490 - val_loss: 0.9680\n",
      "Epoch 800/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9488 - val_loss: 0.9678\n",
      "Epoch 801/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9486 - val_loss: 0.9676\n",
      "Epoch 802/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9484 - val_loss: 0.9674\n",
      "Epoch 803/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9483 - val_loss: 0.9673\n",
      "Epoch 804/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9481 - val_loss: 0.9671\n",
      "Epoch 805/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9479 - val_loss: 0.9669\n",
      "Epoch 806/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9477 - val_loss: 0.9667\n",
      "Epoch 807/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9475 - val_loss: 0.9666\n",
      "Epoch 808/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9474 - val_loss: 0.9664\n",
      "Epoch 809/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9472 - val_loss: 0.9662\n",
      "Epoch 810/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9470 - val_loss: 0.9660\n",
      "Epoch 811/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9468 - val_loss: 0.9659\n",
      "Epoch 812/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9466 - val_loss: 0.9657\n",
      "Epoch 813/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9465 - val_loss: 0.9655\n",
      "Epoch 814/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9463 - val_loss: 0.9654\n",
      "Epoch 815/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9461 - val_loss: 0.9652\n",
      "Epoch 816/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9459 - val_loss: 0.9650\n",
      "Epoch 817/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9458 - val_loss: 0.9648\n",
      "Epoch 818/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9456 - val_loss: 0.9647\n",
      "Epoch 819/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9454 - val_loss: 0.9645\n",
      "Epoch 820/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9452 - val_loss: 0.9643\n",
      "Epoch 821/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9450 - val_loss: 0.9642\n",
      "Epoch 822/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.9449 - val_loss: 0.9640\n",
      "Epoch 823/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9447 - val_loss: 0.9638\n",
      "Epoch 824/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9445 - val_loss: 0.9637\n",
      "Epoch 825/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9443 - val_loss: 0.9635\n",
      "Epoch 826/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9442 - val_loss: 0.9633\n",
      "Epoch 827/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9440 - val_loss: 0.9632\n",
      "Epoch 828/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9438 - val_loss: 0.9630\n",
      "Epoch 829/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9436 - val_loss: 0.9628\n",
      "Epoch 830/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9435 - val_loss: 0.9627\n",
      "Epoch 831/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9433 - val_loss: 0.9625\n",
      "Epoch 832/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9431 - val_loss: 0.9623\n",
      "Epoch 833/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9429 - val_loss: 0.9621\n",
      "Epoch 834/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9428 - val_loss: 0.9620\n",
      "Epoch 835/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9426 - val_loss: 0.9618\n",
      "Epoch 836/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9424 - val_loss: 0.9617\n",
      "Epoch 837/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9423 - val_loss: 0.9615\n",
      "Epoch 838/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9421 - val_loss: 0.9613\n",
      "Epoch 839/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9419 - val_loss: 0.9611\n",
      "Epoch 840/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9417 - val_loss: 0.9610\n",
      "Epoch 841/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9416 - val_loss: 0.9608\n",
      "Epoch 842/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9414 - val_loss: 0.9606\n",
      "Epoch 843/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9412 - val_loss: 0.9605\n",
      "Epoch 844/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9410 - val_loss: 0.9603\n",
      "Epoch 845/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9409 - val_loss: 0.9602\n",
      "Epoch 846/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9407 - val_loss: 0.9600\n",
      "Epoch 847/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9405 - val_loss: 0.9598\n",
      "Epoch 848/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9404 - val_loss: 0.9597\n",
      "Epoch 849/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9402 - val_loss: 0.9595\n",
      "Epoch 850/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9400 - val_loss: 0.9593\n",
      "Epoch 851/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9399 - val_loss: 0.9592\n",
      "Epoch 852/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9397 - val_loss: 0.9590\n",
      "Epoch 853/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9395 - val_loss: 0.9588\n",
      "Epoch 854/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9393 - val_loss: 0.9587\n",
      "Epoch 855/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9392 - val_loss: 0.9585\n",
      "Epoch 856/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9390 - val_loss: 0.9583\n",
      "Epoch 857/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9388 - val_loss: 0.9582\n",
      "Epoch 858/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9387 - val_loss: 0.9580\n",
      "Epoch 859/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9385 - val_loss: 0.9579\n",
      "Epoch 860/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9383 - val_loss: 0.9577\n",
      "Epoch 861/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9382 - val_loss: 0.9575\n",
      "Epoch 862/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9380 - val_loss: 0.9574\n",
      "Epoch 863/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9378 - val_loss: 0.9572\n",
      "Epoch 864/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9377 - val_loss: 0.9570\n",
      "Epoch 865/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9375 - val_loss: 0.9569\n",
      "Epoch 866/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9373 - val_loss: 0.9567\n",
      "Epoch 867/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9372 - val_loss: 0.9566\n",
      "Epoch 868/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9370 - val_loss: 0.9564\n",
      "Epoch 869/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9368 - val_loss: 0.9562\n",
      "Epoch 870/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9367 - val_loss: 0.9561\n",
      "Epoch 871/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9365 - val_loss: 0.9559\n",
      "Epoch 872/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9363 - val_loss: 0.9558\n",
      "Epoch 873/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9362 - val_loss: 0.9556\n",
      "Epoch 874/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9360 - val_loss: 0.9554\n",
      "Epoch 875/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9358 - val_loss: 0.9553\n",
      "Epoch 876/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9357 - val_loss: 0.9551\n",
      "Epoch 877/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9355 - val_loss: 0.9550\n",
      "Epoch 878/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9353 - val_loss: 0.9548\n",
      "Epoch 879/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9352 - val_loss: 0.9546\n",
      "Epoch 880/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9350 - val_loss: 0.9545\n",
      "Epoch 881/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9348 - val_loss: 0.9543\n",
      "Epoch 882/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9347 - val_loss: 0.9542\n",
      "Epoch 883/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9345 - val_loss: 0.9540\n",
      "Epoch 884/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9343 - val_loss: 0.9538\n",
      "Epoch 885/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9342 - val_loss: 0.9537\n",
      "Epoch 886/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9340 - val_loss: 0.9535\n",
      "Epoch 887/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9338 - val_loss: 0.9534\n",
      "Epoch 888/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9337 - val_loss: 0.9532\n",
      "Epoch 889/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9335 - val_loss: 0.9530\n",
      "Epoch 890/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9334 - val_loss: 0.9529\n",
      "Epoch 891/1000\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.9332 - val_loss: 0.9527\n",
      "Epoch 892/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9330 - val_loss: 0.9526\n",
      "Epoch 893/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9329 - val_loss: 0.9524\n",
      "Epoch 894/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9327 - val_loss: 0.9523\n",
      "Epoch 895/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9325 - val_loss: 0.9521\n",
      "Epoch 896/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9324 - val_loss: 0.9519\n",
      "Epoch 897/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9322 - val_loss: 0.9518\n",
      "Epoch 898/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9321 - val_loss: 0.9516\n",
      "Epoch 899/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9319 - val_loss: 0.9515\n",
      "Epoch 900/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9317 - val_loss: 0.9513\n",
      "Epoch 901/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9316 - val_loss: 0.9512\n",
      "Epoch 902/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9314 - val_loss: 0.9510\n",
      "Epoch 903/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9312 - val_loss: 0.9508\n",
      "Epoch 904/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9311 - val_loss: 0.9507\n",
      "Epoch 905/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9309 - val_loss: 0.9505\n",
      "Epoch 906/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9308 - val_loss: 0.9504\n",
      "Epoch 907/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9306 - val_loss: 0.9502\n",
      "Epoch 908/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9304 - val_loss: 0.9501\n",
      "Epoch 909/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9303 - val_loss: 0.9499\n",
      "Epoch 910/1000\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.9301 - val_loss: 0.9498\n",
      "Epoch 911/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9300 - val_loss: 0.9496\n",
      "Epoch 912/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9298 - val_loss: 0.9495\n",
      "Epoch 913/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9297 - val_loss: 0.9493\n",
      "Epoch 914/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9295 - val_loss: 0.9492\n",
      "Epoch 915/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9293 - val_loss: 0.9490\n",
      "Epoch 916/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9292 - val_loss: 0.9489\n",
      "Epoch 917/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9290 - val_loss: 0.9487\n",
      "Epoch 918/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9289 - val_loss: 0.9485\n",
      "Epoch 919/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9287 - val_loss: 0.9484\n",
      "Epoch 920/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9285 - val_loss: 0.9482\n",
      "Epoch 921/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9284 - val_loss: 0.9481\n",
      "Epoch 922/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9282 - val_loss: 0.9479\n",
      "Epoch 923/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9281 - val_loss: 0.9478\n",
      "Epoch 924/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9279 - val_loss: 0.9476\n",
      "Epoch 925/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9278 - val_loss: 0.9475\n",
      "Epoch 926/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9276 - val_loss: 0.9473\n",
      "Epoch 927/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9274 - val_loss: 0.9472\n",
      "Epoch 928/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9273 - val_loss: 0.9470\n",
      "Epoch 929/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9271 - val_loss: 0.9469\n",
      "Epoch 930/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9270 - val_loss: 0.9467\n",
      "Epoch 931/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9268 - val_loss: 0.9466\n",
      "Epoch 932/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9267 - val_loss: 0.9464\n",
      "Epoch 933/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9265 - val_loss: 0.9463\n",
      "Epoch 934/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9263 - val_loss: 0.9461\n",
      "Epoch 935/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9262 - val_loss: 0.9460\n",
      "Epoch 936/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9260 - val_loss: 0.9458\n",
      "Epoch 937/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9259 - val_loss: 0.9457\n",
      "Epoch 938/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9257 - val_loss: 0.9455\n",
      "Epoch 939/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9256 - val_loss: 0.9454\n",
      "Epoch 940/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9254 - val_loss: 0.9452\n",
      "Epoch 941/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9253 - val_loss: 0.9451\n",
      "Epoch 942/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9251 - val_loss: 0.9449\n",
      "Epoch 943/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9250 - val_loss: 0.9448\n",
      "Epoch 944/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9248 - val_loss: 0.9446\n",
      "Epoch 945/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9247 - val_loss: 0.9445\n",
      "Epoch 946/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9245 - val_loss: 0.9443\n",
      "Epoch 947/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9243 - val_loss: 0.9442\n",
      "Epoch 948/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9242 - val_loss: 0.9440\n",
      "Epoch 949/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9240 - val_loss: 0.9439\n",
      "Epoch 950/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9239 - val_loss: 0.9437\n",
      "Epoch 951/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9237 - val_loss: 0.9436\n",
      "Epoch 952/1000\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.9236 - val_loss: 0.9434\n",
      "Epoch 953/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9234 - val_loss: 0.9433\n",
      "Epoch 954/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9233 - val_loss: 0.9432\n",
      "Epoch 955/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.9231 - val_loss: 0.9430\n",
      "Epoch 956/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.9230 - val_loss: 0.9429\n",
      "Epoch 957/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9228 - val_loss: 0.9427\n",
      "Epoch 958/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9227 - val_loss: 0.9426\n",
      "Epoch 959/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9225 - val_loss: 0.9424\n",
      "Epoch 960/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9224 - val_loss: 0.9423\n",
      "Epoch 961/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9222 - val_loss: 0.9421\n",
      "Epoch 962/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9221 - val_loss: 0.9420\n",
      "Epoch 963/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9219 - val_loss: 0.9418\n",
      "Epoch 964/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9218 - val_loss: 0.9417\n",
      "Epoch 965/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9216 - val_loss: 0.9415\n",
      "Epoch 966/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9215 - val_loss: 0.9414\n",
      "Epoch 967/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9213 - val_loss: 0.9413\n",
      "Epoch 968/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9212 - val_loss: 0.9411\n",
      "Epoch 969/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9210 - val_loss: 0.9410\n",
      "Epoch 970/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9209 - val_loss: 0.9408\n",
      "Epoch 971/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9207 - val_loss: 0.9407\n",
      "Epoch 972/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9206 - val_loss: 0.9405\n",
      "Epoch 973/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9204 - val_loss: 0.9404\n",
      "Epoch 974/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9203 - val_loss: 0.9402\n",
      "Epoch 975/1000\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.9201 - val_loss: 0.9401\n",
      "Epoch 976/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9200 - val_loss: 0.9399\n",
      "Epoch 977/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9198 - val_loss: 0.9398\n",
      "Epoch 978/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9197 - val_loss: 0.9397\n",
      "Epoch 979/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9195 - val_loss: 0.9395\n",
      "Epoch 980/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9194 - val_loss: 0.9394\n",
      "Epoch 981/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9192 - val_loss: 0.9392\n",
      "Epoch 982/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9191 - val_loss: 0.9391\n",
      "Epoch 983/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9189 - val_loss: 0.9389\n",
      "Epoch 984/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9188 - val_loss: 0.9388\n",
      "Epoch 985/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9186 - val_loss: 0.9387\n",
      "Epoch 986/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9185 - val_loss: 0.9385\n",
      "Epoch 987/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9183 - val_loss: 0.9384\n",
      "Epoch 988/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9182 - val_loss: 0.9382\n",
      "Epoch 989/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9180 - val_loss: 0.9381\n",
      "Epoch 990/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9179 - val_loss: 0.9380\n",
      "Epoch 991/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9177 - val_loss: 0.9378\n",
      "Epoch 992/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9176 - val_loss: 0.9377\n",
      "Epoch 993/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9175 - val_loss: 0.9375\n",
      "Epoch 994/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9173 - val_loss: 0.9374\n",
      "Epoch 995/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9172 - val_loss: 0.9372\n",
      "Epoch 996/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9170 - val_loss: 0.9371\n",
      "Epoch 997/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9169 - val_loss: 0.9370\n",
      "Epoch 998/1000\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.9167 - val_loss: 0.9368\n",
      "Epoch 999/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9166 - val_loss: 0.9367\n",
      "Epoch 1000/1000\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9164 - val_loss: 0.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7f22713190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(\n",
    "    noised_train, \n",
    "    train, \n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:31:47.695150Z",
     "iopub.status.busy": "2020-11-29T19:31:47.694175Z",
     "iopub.status.idle": "2020-11-29T19:31:47.703836Z",
     "shell.execute_reply": "2020-11-29T19:31:47.702764Z"
    },
    "papermill": {
     "duration": 7.574531,
     "end_time": "2020-11-29T19:31:47.703939",
     "exception": false,
     "start_time": "2020-11-29T19:31:40.129408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(\n",
    "    autoencoder.input, \n",
    "    autoencoder.layers[2].output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:32:00.789756Z",
     "iopub.status.busy": "2020-11-29T19:32:00.788833Z",
     "iopub.status.idle": "2020-11-29T19:32:02.087794Z",
     "shell.execute_reply": "2020-11-29T19:32:02.087220Z"
    },
    "papermill": {
     "duration": 7.579622,
     "end_time": "2020-11-29T19:32:02.087937",
     "exception": false,
     "start_time": "2020-11-29T19:31:54.508315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame(encoder.predict(train))\n",
    "test_features = pd.DataFrame(encoder.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:32:14.642936Z",
     "iopub.status.busy": "2020-11-29T19:32:14.641979Z",
     "iopub.status.idle": "2020-11-29T19:32:14.674095Z",
     "shell.execute_reply": "2020-11-29T19:32:14.674597Z"
    },
    "papermill": {
     "duration": 6.255641,
     "end_time": "2020-11-29T19:32:14.674730",
     "exception": false,
     "start_time": "2020-11-29T19:32:08.419089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.288209</td>\n",
       "      <td>-0.084613</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.794920</td>\n",
       "      <td>0.159032</td>\n",
       "      <td>-0.474173</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>0.191491</td>\n",
       "      <td>-0.663168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401211</td>\n",
       "      <td>0.299418</td>\n",
       "      <td>-0.399510</td>\n",
       "      <td>0.168505</td>\n",
       "      <td>-0.063990</td>\n",
       "      <td>0.122390</td>\n",
       "      <td>0.361761</td>\n",
       "      <td>-0.481489</td>\n",
       "      <td>-0.295739</td>\n",
       "      <td>-0.023230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.489053</td>\n",
       "      <td>0.533348</td>\n",
       "      <td>0.561642</td>\n",
       "      <td>-0.328170</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>1.066271</td>\n",
       "      <td>0.277325</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.450038</td>\n",
       "      <td>0.572256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176148</td>\n",
       "      <td>-0.763831</td>\n",
       "      <td>0.579242</td>\n",
       "      <td>0.595223</td>\n",
       "      <td>-0.309224</td>\n",
       "      <td>0.806332</td>\n",
       "      <td>-0.011253</td>\n",
       "      <td>-0.202415</td>\n",
       "      <td>-0.051660</td>\n",
       "      <td>-0.562452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616431</td>\n",
       "      <td>0.611748</td>\n",
       "      <td>-0.199963</td>\n",
       "      <td>-0.105145</td>\n",
       "      <td>-0.427384</td>\n",
       "      <td>0.296097</td>\n",
       "      <td>1.056623</td>\n",
       "      <td>0.724954</td>\n",
       "      <td>-0.173970</td>\n",
       "      <td>0.388408</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033995</td>\n",
       "      <td>-0.094299</td>\n",
       "      <td>-0.475885</td>\n",
       "      <td>-0.301483</td>\n",
       "      <td>0.979998</td>\n",
       "      <td>-0.032327</td>\n",
       "      <td>-0.224879</td>\n",
       "      <td>0.023184</td>\n",
       "      <td>-0.093343</td>\n",
       "      <td>0.650458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563504</td>\n",
       "      <td>1.198989</td>\n",
       "      <td>0.074572</td>\n",
       "      <td>0.925521</td>\n",
       "      <td>0.249227</td>\n",
       "      <td>0.461288</td>\n",
       "      <td>0.430254</td>\n",
       "      <td>0.438995</td>\n",
       "      <td>-0.571525</td>\n",
       "      <td>-0.482105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.426610</td>\n",
       "      <td>0.778354</td>\n",
       "      <td>0.360439</td>\n",
       "      <td>-0.233763</td>\n",
       "      <td>1.071806</td>\n",
       "      <td>-0.631382</td>\n",
       "      <td>-0.381244</td>\n",
       "      <td>-0.551669</td>\n",
       "      <td>-0.739635</td>\n",
       "      <td>2.615823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.573161</td>\n",
       "      <td>1.223860</td>\n",
       "      <td>0.023006</td>\n",
       "      <td>-0.724670</td>\n",
       "      <td>0.164118</td>\n",
       "      <td>-0.475520</td>\n",
       "      <td>0.739778</td>\n",
       "      <td>0.254715</td>\n",
       "      <td>-0.423146</td>\n",
       "      <td>-0.297135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204772</td>\n",
       "      <td>0.329034</td>\n",
       "      <td>-0.044127</td>\n",
       "      <td>-0.113156</td>\n",
       "      <td>0.172641</td>\n",
       "      <td>-0.161572</td>\n",
       "      <td>0.636598</td>\n",
       "      <td>0.364736</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>-0.620392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>-0.436869</td>\n",
       "      <td>-0.417194</td>\n",
       "      <td>-0.148951</td>\n",
       "      <td>0.316280</td>\n",
       "      <td>0.363389</td>\n",
       "      <td>-0.181390</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.122831</td>\n",
       "      <td>0.084432</td>\n",
       "      <td>0.112713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335282</td>\n",
       "      <td>-0.426890</td>\n",
       "      <td>-0.511917</td>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.150745</td>\n",
       "      <td>-0.173826</td>\n",
       "      <td>0.668973</td>\n",
       "      <td>-0.230216</td>\n",
       "      <td>-0.215054</td>\n",
       "      <td>-0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0.228676</td>\n",
       "      <td>0.433592</td>\n",
       "      <td>-0.168460</td>\n",
       "      <td>0.463091</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>-0.411658</td>\n",
       "      <td>-0.295749</td>\n",
       "      <td>-0.394900</td>\n",
       "      <td>-0.072644</td>\n",
       "      <td>-0.025859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051152</td>\n",
       "      <td>-0.443231</td>\n",
       "      <td>-0.580335</td>\n",
       "      <td>-0.628001</td>\n",
       "      <td>-0.445149</td>\n",
       "      <td>-0.235667</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>-0.475413</td>\n",
       "      <td>-0.415014</td>\n",
       "      <td>-0.550393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>-0.362264</td>\n",
       "      <td>0.181122</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>0.085950</td>\n",
       "      <td>0.204058</td>\n",
       "      <td>0.975244</td>\n",
       "      <td>-0.550869</td>\n",
       "      <td>0.624273</td>\n",
       "      <td>-0.059950</td>\n",
       "      <td>0.232745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205891</td>\n",
       "      <td>-0.074664</td>\n",
       "      <td>-0.021588</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>0.328738</td>\n",
       "      <td>-0.402909</td>\n",
       "      <td>-0.625120</td>\n",
       "      <td>-0.741114</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.360614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>1.643758</td>\n",
       "      <td>0.547342</td>\n",
       "      <td>-0.716092</td>\n",
       "      <td>-0.576418</td>\n",
       "      <td>1.537799</td>\n",
       "      <td>1.580155</td>\n",
       "      <td>0.747167</td>\n",
       "      <td>0.636528</td>\n",
       "      <td>-0.079784</td>\n",
       "      <td>0.195283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.102505</td>\n",
       "      <td>1.732197</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>-0.814156</td>\n",
       "      <td>-0.557487</td>\n",
       "      <td>1.610401</td>\n",
       "      <td>1.181520</td>\n",
       "      <td>-0.713562</td>\n",
       "      <td>-0.595191</td>\n",
       "      <td>-0.218694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>1.255012</td>\n",
       "      <td>0.093840</td>\n",
       "      <td>0.280873</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.647503</td>\n",
       "      <td>-0.567579</td>\n",
       "      <td>-0.398533</td>\n",
       "      <td>-0.275402</td>\n",
       "      <td>-0.592949</td>\n",
       "      <td>-0.892129</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150783</td>\n",
       "      <td>1.150390</td>\n",
       "      <td>-0.271124</td>\n",
       "      <td>-0.910632</td>\n",
       "      <td>0.633945</td>\n",
       "      <td>-0.786949</td>\n",
       "      <td>0.166632</td>\n",
       "      <td>-0.714838</td>\n",
       "      <td>-0.618531</td>\n",
       "      <td>2.712156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.288209 -0.084613  0.306833  0.027031  0.794920  0.159032 -0.474173   \n",
       "1     -0.489053  0.533348  0.561642 -0.328170  0.148360  1.066271  0.277325   \n",
       "2      0.616431  0.611748 -0.199963 -0.105145 -0.427384  0.296097  1.056623   \n",
       "3      0.563504  1.198989  0.074572  0.925521  0.249227  0.461288  0.430254   \n",
       "4     -0.573161  1.223860  0.023006 -0.724670  0.164118 -0.475520  0.739778   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21943 -0.436869 -0.417194 -0.148951  0.316280  0.363389 -0.181390  0.008597   \n",
       "21944  0.228676  0.433592 -0.168460  0.463091  0.029069 -0.411658 -0.295749   \n",
       "21945 -0.362264  0.181122  0.032754  0.085950  0.204058  0.975244 -0.550869   \n",
       "21946  1.643758  0.547342 -0.716092 -0.576418  1.537799  1.580155  0.747167   \n",
       "21947  1.255012  0.093840  0.280873  0.653248  0.647503 -0.567579 -0.398533   \n",
       "\n",
       "           7         8         9     ...      1990      1991      1992  \\\n",
       "0     -0.164630  0.191491 -0.663168  ... -0.401211  0.299418 -0.399510   \n",
       "1      0.488550  0.450038  0.572256  ...  0.176148 -0.763831  0.579242   \n",
       "2      0.724954 -0.173970  0.388408  ...  1.033995 -0.094299 -0.475885   \n",
       "3      0.438995 -0.571525 -0.482105  ...  3.426610  0.778354  0.360439   \n",
       "4      0.254715 -0.423146 -0.297135  ...  0.204772  0.329034 -0.044127   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21943  0.122831  0.084432  0.112713  ...  0.335282 -0.426890 -0.511917   \n",
       "21944 -0.394900 -0.072644 -0.025859  ...  1.051152 -0.443231 -0.580335   \n",
       "21945  0.624273 -0.059950  0.232745  ...  0.205891 -0.074664 -0.021588   \n",
       "21946  0.636528 -0.079784  0.195283  ...  1.102505  1.732197  0.926786   \n",
       "21947 -0.275402 -0.592949 -0.892129  ...  3.150783  1.150390 -0.271124   \n",
       "\n",
       "           1993      1994      1995      1996      1997      1998      1999  \n",
       "0      0.168505 -0.063990  0.122390  0.361761 -0.481489 -0.295739 -0.023230  \n",
       "1      0.595223 -0.309224  0.806332 -0.011253 -0.202415 -0.051660 -0.562452  \n",
       "2     -0.301483  0.979998 -0.032327 -0.224879  0.023184 -0.093343  0.650458  \n",
       "3     -0.233763  1.071806 -0.631382 -0.381244 -0.551669 -0.739635  2.615823  \n",
       "4     -0.113156  0.172641 -0.161572  0.636598  0.364736  0.018596 -0.620392  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21943  0.153921  0.150745 -0.173826  0.668973 -0.230216 -0.215054 -0.192300  \n",
       "21944 -0.628001 -0.445149 -0.235667 -0.006335 -0.475413 -0.415014 -0.550393  \n",
       "21945  0.090602  0.328738 -0.402909 -0.625120 -0.741114  0.003200  0.360614  \n",
       "21946 -0.814156 -0.557487  1.610401  1.181520 -0.713562 -0.595191 -0.218694  \n",
       "21947 -0.910632  0.633945 -0.786949  0.166632 -0.714838 -0.618531  2.712156  \n",
       "\n",
       "[21948 rows x 2000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:32:28.027544Z",
     "iopub.status.busy": "2020-11-29T19:32:28.026670Z",
     "iopub.status.idle": "2020-11-29T19:32:28.030078Z",
     "shell.execute_reply": "2020-11-29T19:32:28.029464Z"
    },
    "papermill": {
     "duration": 6.454726,
     "end_time": "2020-11-29T19:32:28.030186",
     "exception": false,
     "start_time": "2020-11-29T19:32:21.575460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(2000),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(1000)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(1000)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(\n",
    "            tf.keras.layers.Dense(\n",
    "                206, \n",
    "                activation=\"sigmoid\"\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.AdamW(\n",
    "            lr=1e-3, \n",
    "            weight_decay=1e-5, \n",
    "            clipvalue=700\n",
    "        ), \n",
    "        loss='binary_crossentropy'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:32:40.642727Z",
     "iopub.status.busy": "2020-11-29T19:32:40.641305Z",
     "iopub.status.idle": "2020-11-29T19:40:41.447898Z",
     "shell.execute_reply": "2020-11-29T19:40:41.447389Z"
    },
    "papermill": {
     "duration": 487.204441,
     "end_time": "2020-11-29T19:40:41.448008",
     "exception": false,
     "start_time": "2020-11-29T19:32:34.243567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.4278\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0458\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0258\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 2s 15ms/step - loss: 0.0221\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0196\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0189\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0141\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0137\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0133\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0130\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0128\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0124\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0120\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0117\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0114\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0110\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0107\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0104\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0100\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0096\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0092\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0089\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0086\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0082\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0080\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0076\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0073\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0071\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0068\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0065\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0063\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0060\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 2s 16ms/step - loss: 0.0059\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Fold 1\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.4266\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0451\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0257\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0222\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0197\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0148\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0143\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0139\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0136\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0133\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0131\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0127\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0123\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0120\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0116\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0113\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0109\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0106\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0102\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0099\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0095\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0092\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0088\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0085\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0081\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0079\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0076\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0070\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0067\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0064\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0061\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0059\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0054\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.4266\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0451\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0258\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0222\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0194\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0187\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0178\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0142\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0139\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0135\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0133\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0131\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0127\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0124\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0121\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0118\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0115\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0110\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0107\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0104\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0101\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0097\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0094\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0090\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0087\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0084\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0081\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0078\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0075\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0070\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0064\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0062\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0059\n",
      "Fold 3\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.4264\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0457\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0257\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0222\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0195\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0189\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0140\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0137\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0132\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0128\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0125\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0120\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0121\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0116\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0113\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0108\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0105\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0102\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0098\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0095\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0092\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0088\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0085\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0082\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0078\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0076\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0070\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0067\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0065\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0063\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0061\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0059\n",
      "Fold 4\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.4249\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0450\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0255\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0221\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0197\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0189\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0184\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0147\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0142\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0139\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0136\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0132\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0129\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0127\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0124\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0120\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0117\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0112\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0110\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0107\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0102\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0099\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0095\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0092\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0088\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0086\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0083\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0078\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0075\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0066\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0065\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0062\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0060\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0058\n",
      "Fold 5\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.4263\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0451\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0254\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0194\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0184\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 2s 14ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0145\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0140\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0137\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0133\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0131\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0127\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0125\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0121\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0118\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0114\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0111\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0107\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0104\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0101\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0097\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0093\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0090\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0086\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0083\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0082\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0078\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0075\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0072\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0064\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0062\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0060\n",
      "Fold 6\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.4286\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0449\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0257\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0224\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0185\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0177\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0148\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0142\n",
      "Epoch 24/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0141\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0137\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0135\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0132\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0129\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0125\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0122\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0118\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0115\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0111\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0108\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0105\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0102\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0097\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0094\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0091\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0088\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0085\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0082\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0079\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0076\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0072\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0070\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0067\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0065\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0062\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0061\n"
     ]
    }
   ],
   "source": [
    "submission.loc[:, train_targets.columns] = 0\n",
    "res = train_targets.copy()\n",
    "for n, (tr, te) in enumerate(KFold(n_splits=7, random_state=666, shuffle=True).split(train_targets)):\n",
    "    print(f'Fold {n}')\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.fit(\n",
    "        train_features.values[tr],\n",
    "        train_targets.values[tr],\n",
    "        epochs=50, \n",
    "        batch_size=128\n",
    "    )\n",
    "    \n",
    "    submission.loc[:, train_targets.columns] += model.predict(test_features)\n",
    "    res.loc[te, train_targets.columns] = model.predict(train_features.values[te])\n",
    "    \n",
    "submission.loc[:, train_targets.columns] /= (n+1)\n",
    "\n",
    "metrics = []\n",
    "for _target in train_targets.columns:\n",
    "    metrics.append(log_loss(train_targets.loc[:, _target], res.loc[:, _target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:41:00.911613Z",
     "iopub.status.busy": "2020-11-29T19:41:00.910141Z",
     "iopub.status.idle": "2020-11-29T19:41:00.914294Z",
     "shell.execute_reply": "2020-11-29T19:41:00.912278Z"
    },
    "papermill": {
     "duration": 9.45561,
     "end_time": "2020-11-29T19:41:00.914451",
     "exception": false,
     "start_time": "2020-11-29T19:40:51.458841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metric: 0.021527009717644912\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF Metric: {np.mean(metrics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:41:20.182200Z",
     "iopub.status.busy": "2020-11-29T19:41:20.160338Z",
     "iopub.status.idle": "2020-11-29T19:41:20.328210Z",
     "shell.execute_reply": "2020-11-29T19:41:20.327202Z"
    },
    "papermill": {
     "duration": 9.653462,
     "end_time": "2020-11-29T19:41:20.328334",
     "exception": false,
     "start_time": "2020-11-29T19:41:10.674872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['cp_type'] = test_cp_type\n",
    "for col in submission.columns:\n",
    "    if col in ['sig_id', 'cp_type', 'cp_dose', 'cp_time']:\n",
    "        continue\n",
    "    submission.loc[submission['cp_type'] == 'ctl_vehicle', col] = 0\n",
    "\n",
    "submission = submission.drop(['cp_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:41:39.325756Z",
     "iopub.status.busy": "2020-11-29T19:41:39.325040Z",
     "iopub.status.idle": "2020-11-29T19:41:40.970573Z",
     "shell.execute_reply": "2020-11-29T19:41:40.969820Z"
    },
    "papermill": {
     "duration": 11.323604,
     "end_time": "2020-11-29T19:41:40.970685",
     "exception": false,
     "start_time": "2020-11-29T19:41:29.647081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.390677,
     "end_time": "2020-11-29T19:42:00.390790",
     "exception": false,
     "start_time": "2020-11-29T19:41:51.000113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1650.148471,
   "end_time": "2020-11-29T19:42:11.599949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-29T19:14:41.451478",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
