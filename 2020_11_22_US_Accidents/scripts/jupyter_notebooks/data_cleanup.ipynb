{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "#Script for data cleanup of US Accident data\n",
    "\n",
    "Created on Mon Apr 20 21:11:18 2020\n",
    "@author: keino\n",
    "\"\"\"\n",
    "### Description of US Countrywide Traffic Accident Dataset(2016 - 2019)\n",
    "# Source: https://www.kaggle.com/sobhanmoosavi/us-accidents/download\n",
    "\n",
    "# Import Required Libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataset\n",
    "#sys.path.append('/content/drive/My Drive/MSSM/ML_for_BDS')   #change working directory\n",
    "db = pd.read_csv('/Users/ShaunPorwal/Desktop/sinai_classes/BMI3002_ML_2020/MLProject/US_Accidents_Dec19.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step #1. Fix Date and Time Columns\n",
    "#Since there is time and date columns, we can make it easier to work with (taken from Ismael)\n",
    "# Convert Start_Time and End_Time to datetypes\n",
    "db['Start_Time'] = pd.to_datetime(db['Start_Time'], errors='coerce')\n",
    "db['End_Time'] = pd.to_datetime(db['End_Time'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract year, month, day, hour and weekday\n",
    "db['Year']=db['Start_Time'].dt.year\n",
    "db['Month']=db['Start_Time'].dt.strftime('%b')\n",
    "db['Day']=db['Start_Time'].dt.day\n",
    "db['Hour']=db['Start_Time'].dt.hour\n",
    "db['Weekday']=db['Start_Time'].dt.strftime('%a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the amount of time in the unit of minutes for each accident, \n",
    "# round to the nearest integer\n",
    "td='Time_Duration(min)'\n",
    "db[td]=round((db['End_Time']-db['Start_Time'])/np.timedelta64(1,'m'))\n",
    "db.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the rows with td<0\n",
    "neg_outliers=db[td]<=0\n",
    "\n",
    "# Drop rows with negative td\n",
    "db.dropna(subset=[td],axis=0,inplace=True)\n",
    "\n",
    "# Double check to make sure no more negative td\n",
    "db[td].loc[(db[td]>=0)]\n",
    "\n",
    "#Check missing remaining\n",
    "print(db.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Step #2. Deal with tricky geography columns\n",
    "#Drop End LAt and End Lng, since too many are missing and are hard to impute.\n",
    "#They add little value\n",
    "db.drop(labels=['End_Lat', 'End_Lng'],axis=1,inplace=True)\n",
    "\n",
    "#Fill missing street number with a zero\n",
    "db['Number'] = db['Number'].fillna(0)\n",
    "\n",
    "#Impute the timezone, Zipcode and Airport_Code based on the State column\n",
    "db['Timezone'] = db.groupby('State')['Timezone'].transform(lambda tz: tz.fillna(tz.value_counts().index[0]))\n",
    "db['Zipcode'] = db.groupby('State')['Zipcode'].transform(lambda zc: zc.fillna(zc.value_counts().index[0]))\n",
    "db['Airport_Code'] = db.groupby('State')['Airport_Code'].transform(lambda ac: ac.fillna(ac.value_counts().index[0]))\n",
    "\n",
    "#Impute missing city uing most occuring states\n",
    "db['City'] = db.groupby('State')['City'].transform(lambda grp: grp.fillna(grp.value_counts().index[0]))\n",
    "\n",
    "#Check missing remaining\n",
    "print(db.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Step #3. Fix all weather related columns\n",
    "# Fill in NaN with mean values where appropriate\n",
    "fill = ['Temperature(F)','Pressure(in)', 'Humidity(%)','Precipitation(in)', 'Wind_Chill(F)', 'Wind_Speed(mph)', 'Visibility(mi)']\n",
    "for f in fill:\n",
    "    db[f]=db[f].fillna(db[f].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Step #4. Fix all other columns   \n",
    "#Impute time of day-sih columns \n",
    "def median_imputer(x):\n",
    "    db[x].fillna(db[x].mode()[0],inplace=True)\n",
    "\n",
    "median_impute = ['Sunrise_Sunset','Civil_Twilight','Astronomical_Twilight','Wind_Direction','Weather_Condition']\n",
    "for col in median_impute:\n",
    "    median_imputer(col)\n",
    "    \n",
    "# Impute Nautical Twilight, using start time\n",
    "def fill(db,columns):\n",
    "    lst = db[db[columns].isna()].index\n",
    "    for i in lst:\n",
    "        if 6<= db.loc[i,'Start_Time'].hour and db.loc[i,'Start_Time'].hour <18:\n",
    "            db[columns] = db[columns].fillna('Day')\n",
    "        else:\n",
    "            db[columns] = db[columns].fillna('Night')\n",
    "\n",
    "fill(db,'Nautical_Twilight')\n",
    "\n",
    "#weather stamp not really important but can imput by using start time\n",
    "db.loc[(pd.isnull(db.Weather_Timestamp)), 'Weather_Timestamp'] = db.Start_Time\n",
    "\n",
    "#Fill one record in Description with the word 'Accident' #can fill later with most occuring word\n",
    "db.Description = db.Description.fillna('Accident')\n",
    "\n",
    "#Check missing remaining\n",
    "print(db.isnull().sum())\n",
    "\n",
    "#Set up data for Feature Selection \n",
    "X = db.drop(\"Severity\",1)   #Feature Matrix\n",
    "y = db[\"Severity\"]          #Target Variable\n",
    "db.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
